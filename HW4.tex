\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Keep aspect ratio if custom image width or height is specified
    \setkeys{Gin}{keepaspectratio}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \makeatletter
    \newsavebox\pandoc@box
    \newcommand*\pandocbounded[1]{%
      \sbox\pandoc@box{#1}%
      % scaling factors for width and height
      \Gscale@div\@tempa\textheight{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
      \Gscale@div\@tempb\linewidth{\wd\pandoc@box}%
      % select the smaller of both
      \ifdim\@tempb\p@<\@tempa\p@
        \let\@tempa\@tempb
      \fi
      % scaling accordingly (\@tempa < 1)
      \ifdim\@tempa\p@<\p@
        \scalebox{\@tempa}{\usebox\pandoc@box}%
      % scaling not needed, use as it is
      \else
        \usebox{\pandoc@box}%
      \fi
    }
    \makeatother

    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{HW4}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@ges}{\let\PY@bf=\textbf\let\PY@it=\textit}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \section{Fall 2025 CS 4641/7641 Homework
4}\label{fall-2025-cs-46417641-homework-4}

    \subsection{Instructor: Dr.~Mahdi Roozbahani, Dr.~Nimisha
Roy}\label{instructor-dr.-mahdi-roozbahani-dr.-nimisha-roy}

\subsection{Deadline: Tuesday, December 2, 2025 11:59 pm
EST}\label{deadline-tuesday-december-2-2025-1159-pm-est}

\subsubsection{For Homework 4, the December 2nd deadline is a hard and
strict deadline. This means that this deadline cannot be even extended
for students with GT-approved
accomodations.}\label{for-homework-4-the-december-2nd-deadline-is-a-hard-and-strict-deadline.-this-means-that-this-deadline-cannot-be-even-extended-for-students-with-gt-approved-accomodations.}

\begin{itemize}
\item
  No unapproved extension of the deadline is allowed. For late
  submissions, please refer to the course website.
\item
  Discussion is encouraged on Ed as part of the Q/A. We encourage
  whiteboard-level discussions about the homework. \textbf{However, all
  assignments should be done individually.}
\item
  Plagiarism is a \emph{serious offense}. \textbf{You are responsible
  for completing your own work.} You are not allowed to copy and paste,
  or paraphrase, or submit materials created or published by others, as
  if you created the materials. All materials submitted must be your
  own, and you must not collaborate with anyone or share your HW content
  except the ML instructional team.
\item
  Working with a generative-AI platform \emph{may constitute
  plagiarism}. In line with the Joyner Heuristic being used by many
  classes at GT, you should treat collaboration with generative-AI as
  collaboration with a knowledgeable peer. \textbf{Sharing the question
  or your work verbatim with an AI agent so as to generate an answer to
  the question is considered academic dishonesty and will be treated the
  same as any other incident of academic dishonesty.} If you find
  yourself turning to generative-AI for help answering a question, we
  suggest that you instead make use of Ed or TA office hours.
\item
  Even using generative-AI for formatting your answers is \emph{not
  permitted}. \textbf{While we understand that \LaTeX\textasciitilde has
  a learning curve, you may not use any generative-AI platform to
  improve your writing or LaTeX formatting.} These tools inherently
  produce output that may include a partial or complete solution to the
  question, including corrections to work you give it, even if purely
  prompted for syntactic use. Additionally, you have no custody over the
  data you give these platforms, which may leak or be used to inform
  subsequent training. Thus, while you are more than welcome to ask it
  about LaTeX commands and formatting tips, sharing the question or your
  answer to a question verbatim with an AI agent, even purely for
  syntactic use, is considered academic dishonesty and will be treated
  the same as any other incident of academic dishonesty. If you find
  yourself turning to generative-AI for help rewording your work to
  improve the language therein, remember that many of these questions
  will not be graded on language, but the content of your work. If you
  wish to improve it nonetheless, you can make use of the
  \href{https://www.communicationcenter.gatech.edu/}{Georgia Tech
  Communications Lab} or TA office hours. If you find yourself turning
  to generative-AI for help reformatting your LaTeX, we suggest that you
  instead use the resources in the instructions below or TA office
  hours. Ed is also an appropriate place to ask about LaTeX formatting,
  so long as your post doesn't reveal answers to a question (or make a
  private post if your question necessitates revealing answers).
\item
  \emph{All} incidents of suspected dishonesty, plagiarism, or
  violations of the Georgia Tech Honor Code will be subject to the
  institute's Academic Integrity procedures. \textbf{If we observe any
  (even small) similarities/plagiarisms detected by Gradescope or our
  TAs, we will directly report the case to OSI, which may,
  unfortunately, lead to a very harsh outcome, pending review.
  Consequences can be severe, including academic probation or dismissal,
  grade penalties, a 0 grade for assignments concerned, and prohibition
  from withdrawing from the class.}
\end{itemize}

    \subsection{Instructions for the
Assignment}\label{instructions-for-the-assignment}

    \begin{itemize}
\item
  This assignment consists of both programming and theory questions.
\item
  Unless a theory question explicitly states that no work is required to
  be shown, you must provide an explanation, justification, or
  calculation for your answer.
\item
  We will be using Gradescope for submission and grading of assignments.
\item
  \textbf{Unless a question explicitly states that no work is required
  to be shown, you must provide an explanation, justification, or
  calculation for your answer.} Basic arithmetic can be combined (it
  does not need to each have its own step); your work should be at a
  level of detail that a TA can follow it.
\item
  \textbf{For the ``Non-programming'' turn-in of this assignment, you
  will need to submit to Gradescope a PDF copy of your Jupyter Notebook
  with the cells ran.} Please refer to the Deliverables and Point
  Distribution section for an outline of the non-programming questions.
\item
  When submitting your assignment on Gradescope, \textbf{you are
  required to correctly map pages of your PDF to each
  question/subquestion to reflect where your solutions appear in your
  PDF.} For written questions, you should assign every cell relevant to
  the subquestion, including code cells that demonstrate your code
  and/or markdown cells where you write an answer. If you're unsure,
  assign every cell contained in the subquestion. \textbf{Improperly
  mapped questions will receive a 0.} You are permitted to submit a
  regrade request in this event; however, the review of such a request
  is at the sole discretion of the instructional staff and is not likely
  to be accepted.
\item
  \textbf{When submitting to Gradescope, please make sure to mark the
  page(s) corresponding to each problem/sub-problem. The pages in the
  PDF should be of size 8.5'' x 11'' (landscape or portrait), otherwise
  there may be a deduction in points for oversized sheets, up to and
  including full credit deducted.} Again, you are permitted to submit a
  regrade request in this event; however, the review of such a request
  is at the sole discretion of the instructional staff and is not likely
  to be accepted.
\item
  All assignments should be done individually; each student must write
  up and submit their own answers.
\item
  \textbf{Graduate Students}: You are required to complete any sections
  marked as Bonus for Undergrads.
\end{itemize}

    \subsubsection{Using the autograder}\label{using-the-autograder}

\begin{itemize}
\tightlist
\item
  You will find three assignments (for grads) on Gradescope that
  correspond to HW4: ``Assignment 4 Programming'', ``Assignment 4 -
  Non-programming'' and ``Assignment 4 Programming - Bonus for all''.
  Undergrads will have an additional assignment called ``Assignment 4
  Programming - Bonus for Undergrads''.
\item
  You will submit your code for the autograder in the Assignment 4
  Programming sections. Please refer to the Deliverables and Point
  Distribution section for what parts are considered required, bonus for
  undergrads, and bonus for all''.
\item
  We provided you different .py files and we added libraries in those
  files. Please DO NOT remove those lines and add your code after those
  lines. Note that these are the only allowed libraries that you can use
  for the homework. The code you should complete will be contained in
  marked functions.
\item
  You are allowed to make as many submissions until the deadline as you
  like. Additionally, note that the autograder tests each function
  separately, therefore it can serve as a useful tool to help you debug
  your code if you are not sure of what part of your implementation
  might have an issue
\item
  You \textbf{MUST} pass the Autograder Test to gain points for the
  programming section. There will not be any partial credit or manual
  grading for this part.
\end{itemize}

    \subsubsection{\texorpdfstring{Using the local tests
}{Using the local tests }}\label{using-the-local-tests}

\begin{itemize}
\tightlist
\item
  For some of the programming questions we have included a local test
  using a small toy dataset to aid in debugging. The local test sample
  data and outputs are stored in localtests.py
\item
  There are no points associated with passing or failing the local
  tests, you must still pass the autograder to get points.
\item
  \textbf{It is possible to fail the local test and pass the autograder}
  since the autograder has a certain allowed error tolerance while the
  local test allowed error may be smaller. Likewise, passing the local
  tests does not guarantee passing the autograder.
\item
  \textbf{You do not need to pass both local and autograder tests to get
  points, passing the Gradescope autograder is sufficient for credit.}
\item
  It might be helpful to comment out the tests for functions that have
  not been completed yet.
\item
  It is recommended to test the functions as it gets completed instead
  of completing the whole class and then testing. This may help in
  isolating errors. Do not solely rely on the local tests, continue to
  test on the autograder regularly as well.
\end{itemize}

    \subsubsection{Submission Instructions}\label{submission-instructions}

Do not add or remove imports from any files, as this will cause the
autograder to fail to parse your solution.

For actual submission to Gradescope, upload the following files:

\begin{itemize}
\item
  \textbf{Assignment 4 Programming}

  \begin{itemize}
  \tightlist
  \item
    NN.py
  \item
    cnn\_image\_transformations.py
  \item
    cnn.py
  \item
    cnn\_trainer.py
  \end{itemize}
\item
  \textbf{Assignment 4 Programming - Bonus for All}

  \begin{itemize}
  \tightlist
  \item
    rnn.py
  \item
    lstm.py
  \item
    base\_sequential\_model.py (you don't need to modify this file but
    need to submit it)
  \end{itemize}
\item
  \textbf{Assignment 4 Programming - Bonus for Undergrad}

  \begin{itemize}
  \tightlist
  \item
    NN.py
  \item
    cnn\_image\_transformations.py
  \item
    cnn.py
  \item
    cnn\_trainer.py
  \end{itemize}
\item
  \textbf{Assignment 4 Non-Programming}

  \begin{itemize}
  \tightlist
  \item
    You will need to submit to Gradescope a PDF copy of your Jupyter
    Notebook with the cells ran. Please refer to the
    \textbf{Deliverables and Point Distribution} section for an outline
    of the non-programming questions. Complete the notebook, then use
    some tool to convert this notebook into a pdf.
  \item
    It is your responsibility to make sure that all LaTeX renders, all
    generated matplotlib figures render, none of your answers are
    clipped, the font is a reasonable size, the pdf is a reasonable
    resolution, the pdf is the correct size (8.5''x11''). Failure to do
    so may result in heavy penalties.
  \item
    It is also your responsibility to correctly assign pages to the
    relevant subquestions. If you are unsure what is being graded, to be
    safe, you may submit any page containing content for the entire
    subquestion.
  \end{itemize}
\end{itemize}

    \subsection{Deliverables and Points
Distribution}\label{deliverables-and-points-distribution}

    \subsubsection{Q1: Classification with Two Layer NN {[}89pts: 64pts +
25pts Grad / 3.6\% Bonus for
Undergrad{]}}\label{q1-classification-with-two-layer-nn-89pts-64pts-25pts-grad-3.6-bonus-for-undergrad}

    \paragraph{Deliverables: NN.py}\label{deliverables-nn.py}

\begin{itemize}
\item
  \textbf{1.1 NN Implementation} {[}57pts: 47pts + 10pts Grad / 1.6\%
  \textbf{Bonus for Undergrad}{]} - \emph{programming},
  \emph{non-programming}

  \begin{itemize}
  \tightlist
  \item
    1.1.1 Weight Initialization {[}2pts{]}
  \item
    1.1.2 Softmax {[}2.5pts{]}
  \item
    1.1.3 Softsign {[}2.5pts{]}
  \item
    1.1.4 Dropout {[}5pts{]}
  \item
    1.1.5 Cross Entropy loss {[}2.5pts{]}
  \item
    1.1.6 Forward propagation with and without dropout {[}10pts{]}
  \item
    1.1.7 Compute gradients {[}7.5pts{]}
  \item
    1.1.8 Update gradients without Adam {[}5pts{]}
  \item
    1.1.9 Update gradients with Adam {[}5pts / 0.8\% \textbf{Bonus for
    Undergrad}{]}
  \item
    1.1.10 Backward {[}5pt{]}
  \item
    1.1.11 Gradient Descent {[}2.5pt{]}
  \item
    1.1.12 Mini-batch Gradient Descent {[}2.5pts{]}
  \item
    1.1.13 Gradient Descent with Adam {[}2.5pts / 0.4\% \textbf{Bonus
    for Undergrad}{]}
  \item
    1.1.14 Mini-batch Gradient Descent with Adam {[}2.5pts / 0.4\%
    \textbf{Bonus for Undergrad}{]}
  \end{itemize}
\item
  \textbf{1.2 Training with Gradient Descent} {[}9.5pts{]} -
  \emph{programming}, \emph{non-programming}

  \begin{itemize}
  \tightlist
  \item
    1.2.1 Loss plot and cross-entropy (CE) value {[}7.5pts{]}
  \item
    1.2.2 Learning Rates {[}2pts{]}
  \end{itemize}
\item
  \textbf{1.3 Training with Mini-batch Gradient Descent} {[}7.5pts{]} -
  \emph{programming}
\item
  \textbf{1.4 Training with Gradient Descent and Adam} {[}7.5pts Grad /
  1\% \textbf{Bonus for Undergrad}{]} - \emph{programming}
\item
  \textbf{1.5 Training with Mini-batch Gradient Descent and Adam}
  {[}7.5pts Grad / 1\% \textbf{Bonus for Undergrad}{]} -
  \emph{programming}
\end{itemize}

    \subsubsection{Q2: Image Classification based on CNNs {[}26pts: 10pts +
16pts Grad / 2.4\% Bonus for Undergrad + 2.5\% Bonus for
All{]}}\label{q2-image-classification-based-on-cnns-26pts-10pts-16pts-grad-2.4-bonus-for-undergrad-2.5-bonus-for-all}

    \paragraph{Deliverables: cnn.py, cnn\_trainer.py,
cnn\_image\_transformations.py and Written
Report}\label{deliverables-cnn.py-cnn_trainer.py-cnn_image_transformations.py-and-written-report}

\begin{itemize}
\item
  \textbf{2.1 Image Classification using Pytorch CNN} {[}26pts: 10pts +
  16pts Grad / 2.4\% \textbf{Bonus for Undergrad}{]} -
  \emph{programming}

  \begin{itemize}
  \tightlist
  \item
    2.1.1 Data Augmentation {[}5pts{]}
  \item
    2.1.2 Building the Model {[}5pts{]}
  \item
    2.1.3 Training and Tuning the Model {[}12pts Grad / 1.8\%
    \textbf{Bonus for Undergrad}{]}
  \item
    2.1.4 Examining Loss Plots {[}2pts Grad / 0.3\% \textbf{Bonus for
    Undergrad}{]}
  \item
    2.1.5 Evaluating Confusion Matrix {[}2pts Grad / 0.3\% \textbf{Bonus
    for Undergrad}{]}
  \end{itemize}
\item
  \textbf{2.2 Exploring Deep CNN Architectures} {[}2.5\% \textbf{Bonus
  for All}{]} - \emph{non-programming}

  \begin{itemize}
  \tightlist
  \item
    2.2.1 Abating Vanishing Gradients {[}1.5\% Bonus for All{]}
  \item
    2.2.2 Abating Internal Covariate Shift {[}1.0\% Bonus for All{]}
  \end{itemize}
\end{itemize}

    \subsubsection{Q3: SVM {[}20 pts{]}}\label{q3-svm-20-pts}

    \paragraph{Deliverables: svm.py and Written
Report}\label{deliverables-svm.py-and-written-report}

\begin{itemize}
\item
  \textbf{3.1 Picking Performant Constructions} {[}5pts{]} -
  \emph{non-programming}
\item
  \textbf{3.2 Custom Feature Engineering} {[}5pts{]} -
  \emph{programming}
\item
  \textbf{3.3 Kernel Trick} {[}10pts{]}

  \begin{itemize}
  \tightlist
  \item
    3.3.1 Build a Kernel {[}5pts{]} - \emph{programming}
  \item
    3.3.2 Build a Known Kernel (RBF) {[}5pts{]} - \emph{programming}
  \end{itemize}
\end{itemize}

    \subsubsection{Q4: Next Character Prediction using Recurrent Neural
Networks (RNNs) {[}7.5\% Bonus for
all{]}}\label{q4-next-character-prediction-using-recurrent-neural-networks-rnns-7.5-bonus-for-all}

    \paragraph{Deliverables: rnn.py, lstm.py and Written
Report}\label{deliverables-rnn.py-lstm.py-and-written-report}

\begin{itemize}
\item
  \textbf{4.1: Model Architecture} {[}5\% \textbf{Bonus for All}{]} -
  \emph{programming}

  \begin{itemize}
  \tightlist
  \item
    4.1.1: Defining the Simple RNN model {[}2.5\% \textbf{Bonus for
    All}{]}
  \item
    4.1.2: Defining the LSTM model {[}2.5\% \textbf{Bonus for All}{]}
  \end{itemize}
\item
  \textbf{4.2: Simple RNN vs LSTM Model Text Generation Training
  Comparison Analysis} {[}2.5\% \textbf{Bonus for All}{]} -
  \emph{non-programming}
\end{itemize}

    \subsubsection{Point Totals}\label{point-totals}

    \begin{itemize}
\item
  Total Base: 135pts for grads / 94pts for undergrads

  \begin{itemize}
  \tightlist
  \item
    Programming: 126pts for grads / 85pts for undergrads
  \item
    Written: 9pts
  \end{itemize}
\item
  Total Undergrad Bonus: 6\%

  \begin{itemize}
  \tightlist
  \item
    Programming: 6\%
  \item
    Written: 0\%
  \end{itemize}
\item
  Total Bonus for All: 10\%

  \begin{itemize}
  \tightlist
  \item
    Programming: 5\%
  \item
    Written: 5\%
  \end{itemize}
\end{itemize}

    \subsection{Environment Setup}\label{environment-setup}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{os}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{random}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{sys}

\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{matplotlib}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{plt}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{numpy}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{np}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{pandas}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{pd}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{requests}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{torch}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{cnn}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{CNN}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{cnn\PYZus{}image\PYZus{}transformations}\PY{+w}{ }\PY{k+kn}{import} \PY{p}{(}
    \PY{n}{TransformedDataset}\PY{p}{,}
    \PY{n}{create\PYZus{}testing\PYZus{}transformations}\PY{p}{,}
    \PY{n}{create\PYZus{}training\PYZus{}transformations}\PY{p}{,}
\PY{p}{)}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{get\PYZus{}housing\PYZus{}dataset}\PY{p}{,} \PY{n}{get\PYZus{}mri\PYZus{}dataset}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Version information}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{python: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{sys}\PY{o}{.}\PY{n}{version}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{matplotlib: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{matplotlib}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{numpy: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{)}

\PY{o}{\PYZpc{}}\PY{k}{load\PYZus{}ext} autoreload
\PY{o}{\PYZpc{}}\PY{k}{autoreload} 2
\PY{o}{\PYZpc{}}\PY{k}{reload\PYZus{}ext} autoreload
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Version information
python: 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:13:34) [MSC
v.1944 64 bit (AMD64)]
matplotlib: 3.10.8
numpy: 2.3.4
    \end{Verbatim}

    \subsection{Coding and Emissions}\label{coding-and-emissions}

    Coding and computational research contribute to greenhouse gas
emissions. The main source of these emissions is the power draw of
computers during compute- and data-intensive computational analyses. In
2020, the sector of information and communication technologies was
responsible for between 1.8\% and 2.8\% of GHG emissions, surprisingly
more than the sector of aviation {[}1{]}. Machine learning models,
especially large ones, can consume significant amounts of energy during
training and inference, which contributes to greenhouse gas emissions.
Artificial intelligence, including large language models, is also a
significant emitter of carbon {[}2{]}.

Carbon footprint of coding impacts several Sustainable Development Goals
(SDGs), particularly SDG 13 (Climate Action) and SDG 12 (Responsible
Consumption and Production).{[}3{]} This means writing clean and
efficient code transcends functionality---it's an environmental
imperative. As coders, we can play a role in mitigating this impact.

\subsubsection{Measuring Our Impact:}\label{measuring-our-impact}

CodeCarbon estimates the amount of CO2 produced by the cloud or personal
computing resources used to execute the code{[}4{]} .

Using CodeCarbon in your upcoming assignment will help you understand
the environmental impact of your code and explore ways to reduce it.

The code below will start tracking your carbon consumption and will
print out total consumption at the end of the notebook.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{codecarbon}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{EmissionsTracker}

\PY{n}{emissions\PYZus{}dir} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./emissions}\PY{l+s+s2}{\PYZdq{}}
\PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{emissions\PYZus{}dir}\PY{p}{)}\PY{p}{:}
    \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{emissions\PYZus{}dir}\PY{p}{)}
\PY{n}{tracker} \PY{o}{=} \PY{n}{EmissionsTracker}\PY{p}{(}
    \PY{n}{log\PYZus{}level}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{n}{save\PYZus{}to\PYZus{}file}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
    \PY{n}{output\PYZus{}dir}\PY{o}{=}\PY{n}{emissions\PYZus{}dir}\PY{p}{,}
    \PY{n}{allow\PYZus{}multiple\PYZus{}runs}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
\PY{p}{)}
\PY{n}{tracker}\PY{o}{.}\PY{n}{start}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[codecarbon WARNING @ 14:44:56] Multiple instances of codecarbon are allowed to
run at the same time.
    \end{Verbatim}

    \subsection{\texorpdfstring{Q1: Two Layer Neural Network {[}89 pts:
64pts + 25pts Grad / 3.6\% Undergrad Bonus{]} {\textbf{{[}P{]}}}
\textbar{}
{\textbf{{[}W{]}}}}{Q1: Two Layer Neural Network {[}89 pts: 64pts + 25pts Grad / 3.6\% Undergrad Bonus{]} {[}P{]} \textbar{} {[}W{]}}}\label{q1-two-layer-neural-network-89-pts-64pts-25pts-grad-3.6-undergrad-bonus-p-w}

    \subsubsection{Neural Net Recap}\label{neural-net-recap}

    A perceptron can be thought of as a linear hyperplane, as seen in
logistic regression and SVM, followed by a non-linear activation
function, warping ths space, allowing the final decision to capture
non-linear patterns. If we have a \(D\)-dimensional input vector
\(x \in \mathbb{R}^D\) (one datapoint with \(D\) features), a perceptron
is defined by a raw activation \(u\), the activation function
\(\phi:\mathbb{R}\rightarrow\mathbb{R}\), and the ouput \(o\). To make
the linear hyperplane, we weight each feature by some value \(\theta_j\)
and add on a bias at the end \(b\).

\[u = \theta^{T}x+b\]
\[o = \phi(u) = \phi\left( \sum \limits_{j=1}^D \theta_{j}x_j+b \right)\]

There's nothing stopping us from making more perceptrons, though, each
with their own weight vectors. We could have a whole output layer \(o\):

\[o_i = \phi(u_i) = \phi\left( \sum \limits_{j=1}^D \theta_{ij}x_j+b_i \right)\]

Now, \(\theta\) is a matrix {[}input dims{]} x {[}number of output
perceptrons{]}, and \(b\) is a vector {[}input dims{]}. This can indeed
be thought of as a matrix operation, where we apply phi to every
component of the output:

\[o_i = \phi\left( \boldsymbol{\theta}\vec{x}+\vec{b} \right)\]

The key insight behind neural networks is to use the output layer as a
new input layer, and stack this operation! If our single layer can
capture a few patterns, multiple layers should be able to capture very
complex patterns.

    Typically, a modern neural network contains millions of perceptrons. In
this part, we describe a fully connected layer in a neural network which
comprises multiple perceptrons in every layer.

We extend the previous notation to describe a fully connected layer.
Each layer in a fully connected network has a number of
input/hidden/output units cascaded in parallel. Let us a define a single
layer of the neural net as follows: \(m\) denotes the number of hidden
units in a single layer \(l\) whereas \(n\) denotes the number of units
in the previous layer \(l-1\). \[u^{[l]}=\theta^{[l]}o^{[l-1]}+b^{[l]}\]
where \(u^{[l]} \in R^{m}\) is a m-dimensional vector pertaining to the
hidden units of the \(l^{th}\) layer of the neural network after
applying linear operations. Similarly, \(o^{[l-1]} \in R^{n}\) is the
n-dimensional output vector corresponding to the hidden units of the
\((l-1)^{th}\) activation layer. \(\theta^{[l]} \in R^{m \times n}\) is
the weight matrix of the \(l^{th}\) layer where each row of
\(\theta^{[l]}\) is analogous to \(\theta_{i}\) described in the
previous section i.e.~each row corresponds to one hidden unit of the
\(l^{th}\) layer. \(b^{[l]} \in R^{m}\) is the bias vector of the layer
where each element of b pertains to one hidden unit of the \(l^{th}\)
layer. This is followed by element wise non-linear activation function
\(o^{[l]} = \phi(u^{[l]})\). The whole operation can be summarized as,
\[o^{[l]} = \phi(\theta^{[l]}o^{[l-1]}+b^{[l]}) \] where \(o^{[l-1]}\)
is the output of the previous layer.

    As for the activation function, it really just needs to be non-linear.
Some functions are preferred in some places, sometimes due to their
gradient, sometimes due to some statistical guarantees for a theoretical
analysis, but really, your choice of activation function is just another
hyperparameter to throw in the hyperparameter soup.

There are many activation functions that are used for various purposes.
For this question, we use softsign and the softmax activation functions.
In your project, or personal work, we encourage you to explore
\href{https://en.wikipedia.org/wiki/Activation_function}{the plethora of
options}.

The one activation function that you need to be really careful with is
the last one. If you want your network to output a probability
distribution, you should make the activation function map to the range
{[}0,1{]} and divide by the sum (to make it sum to 1). If you want your
network to output a non-negative number, you should make the activation
function map to the range (0,inf), maybe exp or relu. This will
determine the outputs your network can possibly learn, so make sure all
of your training targets are in the range of your final activation.

    \subsubsection{\texorpdfstring{1.1 NN Implementation {[}57pts: 47pts +
10pts Grad / 1.6\% Bonus for Undergrad{]} {\textbf{{[}P{]}}} \textbar{}
{\textbf{{[}W{]}}}}{1.1 NN Implementation {[}57pts: 47pts + 10pts Grad / 1.6\% Bonus for Undergrad{]} {[}P{]} \textbar{} {[}W{]}}}\label{nn-implementation-57pts-47pts-10pts-grad-1.6-bonus-for-undergrad-p-w}

    In this section, you will implement a two layer fully connected neural
network to perform a Classification Task. You will also experiment with
different activation functions and optimization techniques. We provide
two activation functions here - Softsign and Softmax. You will implement
a neural network where the first hidden layer uses a Softsign activation
and the output layer uses Softmax.

You'll also implement Gradient Descent (GD) and Mini-batch Gradient
Descent (MBGD) algorithms for training these neural nets. In the NN.py
file, complete the following functions:

\begin{itemize}
\tightlist
\item
  softmax
\item
  softsign
\item
  derivative\_softsign
\item
  \_dropout
\item
  cross\_entropy\_loss
\item
  forward
\item
  compute\_gradients
\item
  update\_weights
\item
  backward
\item
  gradient\_descent
\item
  minibatch\_gradient\_descent
\end{itemize}

We'll train this neural network on sklearn's California Housing dataset.

    \paragraph{1.1.1 Weight Initialization}\label{weight-initialization}

    {\textbf{{[}W{]}} Please assign all pages containing your answer to the
question.}

Weight initialization is the process of setting the initial values of
the weights and biases of a neural network prior to training. We have
already implemented the weight initialization for this neural network.
Specifically, we used a variant of the Xavier initialization, which can
be defined as:

\[W = \frac{randn(n_{in}, n_{out})}{\sqrt{n_{in}}}\]

Read these two sources about Xavier initialization. -
\href{https://www.geeksforgeeks.org/deep-learning/xavier-initialization/}{Geeks
for Geeks Summary} -
\href{https://proceedings.mlr.press/v9/glorot10a}{Original paper}

Explain what the goal of Xavier initialization is and how it helps in
neural network training. Then, briefly describe how the variant we
provided reflects the same idea, even though it uses a slightly
different formula.

    \textbf{YOUR ANSWER HERE}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

The goal of Xavier initialization is to prevent gradients from vanishing
or exploding by keeping the variance of activations and gradients
consistent across all layers of the network. This stability ensures that
signals propagate effectively during training without driving activation
functions into saturation, which would stall the learning process. Our
variant similarly scales the initial random weights by the square root
of the number of input units (\({1}/{\sqrt{n_{\text{in}}}}\)),
normalizing the variance to maintain a stable signal during the forward
pass.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \paragraph{1.1.2 Softmax}\label{softmax}

    Softmax is a common activation function used in neural networks,
especially for multiclass classification problems like the one we are
tackling. It is used to convert a vector of raw outputs from the last
layer of the Neural Network into a probability distribution over
multiple classes. The softmax function takes as input a vector of real
numbers and transforms them into a probability distribution, ensuring
that the probabilities sum to 1.

Mathematically, given an input vector of {[}x1, x2, \ldots, xn{]}, the
softmax function calculates the probability p(y=i) for each class i as
follows:

p(y=i) = \(e^{xi} / (e^{x1} + e^{x2} + ... + e^{xn})\)

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio,alt={sigmoid}]{data/images/softmax.png}}
\caption{sigmoid}
\end{figure}

As discussed in class, the equation that we will use in this Neural
network accounts for both the x values and the weights:

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio,alt={sigmoid}]{data/images/softmaxNew.jpg}}
\caption{sigmoid}
\end{figure}

TODO: Implement the function softmax in NN.py.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}softmax}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}softmax}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_softmax passed!
    \end{Verbatim}

    \paragraph{1.1.3 Softsign}\label{softsign}

    The Softsign activation function, is defined as:

\[
o = \phi(u) = \frac{u}{1 + |u| }
\]

The derivative of Softsign, \(\phi'(u)\), is given by:

\[
\phi'(u) = \frac{1}{(1 + |u|)^2 }
\]

Unlike ReLU, Softsign is a smooth and non-linear activation function
that gradually approaches 1 and 1 for large negative and positive
inputs, respectively. This smoothness helps stabilize training by
reducing sharp gradient changes and improving gradient flow compared to
ReLU.

In this homework, we implement Softsign.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio,alt={Softsign}]{data/images/softsign_and_derivative.png}}
\caption{Softsign}
\end{figure}

TODO: Implement the function softsign and derivative\_softsign in NN.py.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}softsign}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}softsign}\PY{p}{(}\PY{p}{)}
\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}d\PYZus{}softsign}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}d\PYZus{}softsign}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_softsign passed!
test\_d\_softsign passed!
    \end{Verbatim}

    \paragraph{1.1.4 Dropout}\label{dropout}

    A dropout layer is a regularization technique used in neural networks to
reduce overfitting. During training, a dropout layer looks at each input
unit and randomly decide if it will be dropped (set to zero) with some
given probability \(p\). The decision for each unit is made
independently. Formally, given an input of shape \(N \times K\) (where
\(N\) is the number of data points and \(K\) is the number of features),
it samples from \(\text{Bernoulli}(p)\) for each unit, resulting in an
output where approximately \(pNK\) of the units are zero (in
expectation). This forces the network to learn more robust and
generalizable features, since it cannot rely too much on any particular
input. During inference, the dropout layer is turned off, and the full
network is used to make predictions.

The dropout probability \(p\) is a hyperparameter than can be tuned to
adjust the strength of regularization. Setting \(p=0\) is equivalent to
no dropout.

Note that the derivative of \(\text{dropout}(u)\) with respect to \(u\)
has the same shape as \(u\). The values of the derivative depend on the
random mask.

Use
\href{https://d2l.ai/chapter_multilayer-perceptrons/dropout.html}{this}
as a reference for your implementation.

Note that after applying the mask, we must scale the result by a factor
of \(1/(1-p)\). Why is this necessary?

TODO: Implement the \_dropout function in NN.py.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}dropout}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}dropout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_dropout passed!
    \end{Verbatim}

    \paragraph{1.1.5 Cross Entropy Loss}\label{cross-entropy-loss}

    Cross-Entropy Loss is a widely used loss function in machine learning
and deep learning, especially for classification tasks. It measures the
dissimilarity between the predicted probability distribution and the
true probability distribution of a classification problem. If it is
closer to zero, the better the learnt function is.

For classification problems as in this exercise, we compute the loss as
follows:

\[CE = -\frac{1}{N}\sum\limits_{i=1}^{N}\left(y_{i} \cdot log(\hat{y_{i}})\right)\]

where \(y_{i}\) is the true label and \(\hat{y_{i}}\) is the estimated
label. Here, \(y_i\)/\(\hat{y_i}\) are (1 x D) vectors and
\(y\)/\(\hat{y}\) are (N x D) vectors.

TODO: Implement the cross\_entropy\_loss function in NN.py.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}loss}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_loss passed!
    \end{Verbatim}

    \paragraph{Our Neural Network
Architecture}\label{our-neural-network-architecture}

    Now we will build a two layer neural network consisting of two hidden
layers, each followed by a Softsign activation function. The logits
outputted by the second hidden linear layer are then passed through the
softmax function, which turns them into probability distributions over
the 3 classes. Mathematically,

\begin{align*}
u_1 &= \boldsymbol{\theta_1} x + b_1 \\
o_1 &= \text{dropout}(\text{softsign}(u_1), p) \\
u_2 &= \boldsymbol{\theta_2} o_1 + b_2 \\
o_2 &= \text{softsign}(u_2)\\
u_3 &= \boldsymbol{\theta_3} o_2 + b_3\\
o_3 &= \text{softmax}(u_3)\\
l &= \text{cross\_entropy}(o_3)
\end{align*}

Here is a diagram of the same architecture:

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio,alt={Neural Network}]{data/images/neural_net_diagram.jpg}}
\caption{Neural Network}
\end{figure}

    \paragraph{1.1.6 Forward Pass}\label{forward-pass}

    TODO: Implement the forward function in NN.py.

Follow the equations given above to implement a full forward pass
through the network. More details in the function description.

Here is a helpful
\href{https://static.us.edusercontent.com/files/gznuqr6aWHD8dPhiusG2TG53}{guide}
that walks through the matrix multiplication operations and shapes
involved in a forward and backward pass.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}forward\PYZus{}without\PYZus{}dropout}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}forward\PYZus{}without\PYZus{}dropout}\PY{p}{(}\PY{p}{)}
\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}forward\PYZus{}with\PYZus{}dropout}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}forward\PYZus{}with\PYZus{}dropout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_forward\_without\_dropout passed!
test\_forward passed!
    \end{Verbatim}

    \paragraph{1.1.7 Compute Gradients}\label{compute-gradients}

    After the forward pass, we do back propagation to update the weights and
biases in the direction of the negative gradient of the loss function.

    In order to compute the gradients of the loss with respect to each
parameter, we use the equations that make up the forward pass:
\begin{align*}
u_1 &= \theta_1 x + b_1 \\
o_1 &= \text{softsign}(u_1) \\
u_2 &= \theta_2 o_1 + b_2 \\
o_2 &= \text{softsign}(u_2)\\
u_3 &= \theta_3 o_2 + b_3\\
o_3 &= \text{softmax}(u_3) \\
l &= \text{cross\_entropy}(o_3)
\end{align*}

When computing gradients, we travel backwards from the loss all the way
back to the input. We first seek to obtain the derivative of the loss
\(l\) with respect to the logits \(u_3\). Note that they have the
relation \[ l = \text{cross\_entropy}(\text{softmax}(u_3))\] Computing
the derivative of this seems very involved, but it actually has a very
elegant result:
\[ \frac{\partial l}{\partial u_3} = \text{softmax}(u_3) - y = o_3 - y = \hat{y} - y. \]
where \(\hat{y}\) is predicted y or \(o_3\).

While this is given to you, we encourage you to derive it for yourself!
You can find a great explanation of the derivation
\href{https://medium.com/towards-data-science/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1}{in
this article}.

Now that we have \(\frac{\partial l}{\partial u_3}\), we seek to move
further back and compute \(\frac{\partial l}{\partial \theta_3}\) and
\(\frac{\partial l}{\partial b_3}\). This is done using the chain rule:
\begin{align*}
\frac{\partial l}{\partial \theta_3} &= \frac{\partial l}{\partial u_3} \cdot \frac{\partial u_3}{\partial \theta_3} \\
\frac{\partial l}{\partial b_3} &= \frac{\partial l}{\partial u_3} \cdot \frac{\partial u_3}{\partial b_3}.
\end{align*}

The quantities \(\frac{\partial u_3}{\partial \theta_3}\) and
\(\frac{\partial u_3}{\partial b_3}\) are easy to derive from the
relation \(u_3 = \theta_3 o_2 + b_3\). We see that \begin{align*}
\frac{\partial l}{\partial \theta_3} &= \frac{\partial l}{\partial u_3} \cdot o_2 \\
\frac{\partial l}{\partial b_3} &= \frac{\partial l}{\partial u_3} \cdot 1.
\end{align*}

Note that the derivative involves \(o_2\), which we computed during the
forward pass. Fortunately, we saved that value in \texttt{self.cache},
so we don't need to compute it again!

The same procedure is repeated to obtain the gradients for the upstream
parameters \(\theta_2\) and \(b_2\). We must first perform the
intermediate steps of computing the derivative of the loss with respect
to \(o_2\) and then \(u_2\). These are given by \begin{align*}
\frac{\partial l}{\partial o_2} &= \frac{\partial l}{\partial u_3} \cdot \theta_3 \\
\frac{\partial l}{\partial u_2} &= \frac{\partial l}{\partial o_2} \cdot \frac{\partial\,\text{Softsign}}{\partial u_2}.
\end{align*}

The same procedure is repeated to obtain the gradients for the upstream
parameters \(\theta_1\) and \(b_1\). We must first perform the
intermediate steps of computing the derivative of the loss with respect
to \(o_1\) and then \(u_1\). These are given by \begin{align*}
\frac{\partial l}{\partial o_1} &= \frac{\partial l}{\partial u_2} \cdot \theta_2 \\
\frac{\partial l}{\partial u_1} &= \frac{\partial l}{\partial o_1} \cdot \frac{\partial\,\text{Softsign}}{\partial u_1}.
\end{align*}

In the second relation, we must consider our use of dropout! If we
applied dropout on a particular neuron, it should not be adjusted. To
account for this, in the case of \texttt{use\_dropout=True}, we must
instead use
\[ \frac{\partial l}{\partial u_1} = \frac{\partial l}{\partial o_1} \cdot \frac{\partial\,\text{Softsign}}{\partial u_1} \cdot \text{dropout\_mask} \cdot \frac{1}{1-p}, \]
where \(1 / (1-p)\) is the scaling factor and dropout\_mask is stored in
\texttt{self.cache}.

The final step! We can use these values to compute the gradients for
\(\theta_1\) and \(b_1\), using the relation \(u_1 = \theta_1 X + b_1\),
which are given by \begin{align*}
\frac{\partial l}{\partial \theta_1} &= \frac{\partial l}{\partial u_1} \cdot X \\
\frac{\partial l}{\partial b_1} &= \frac{\partial l}{\partial u_1} \cdot 1.
\end{align*}

    The above equations are given in matrix notation. When implementing
these computations in code, the easiest way to make sure you are
calculating the values correctly and in the right order is to check
shapes. Any time you are doing a matrix/vector operation in NumPy,
\textbf{check the shapes}.

Since we are computing these gradients over \(N\) data points, we must
divide the gradients by \(N\) to take the \emph{average} gradient. Make
sure you are dividing by \(N\) exactly once, no more and no less!

TODO: Implement the compute\_gradients function in NN.py.

Note: Implement drop out function only on the first hidden layer!

Hint: Refer to this
\href{https://static.us.edusercontent.com/files/gznuqr6aWHD8dPhiusG2TG53}{guide}
for more detail on computing gradients.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}compute\PYZus{}gradients\PYZus{}without\PYZus{}dropout}\PY{l+s+s2}{\PYZdq{}}
\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}compute\PYZus{}gradients\PYZus{}without\PYZus{}dropout}\PY{p}{(}\PY{p}{)}
\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}compute\PYZus{}gradients\PYZus{}with\PYZus{}dropout}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}compute\PYZus{}gradients\PYZus{}with\PYZus{}dropout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_compute\_gradients\_without\_dropout passed!
test\_compute\_gradients\_with\_dropout passed!
    \end{Verbatim}

    \paragraph{1.1.8 Update Weights}\label{update-weights}

    So, we update the weights and biases using the following formulas
\begin{align*}
\theta^{[3]} := \theta^{[3]} - lr \times \frac{\partial l}{\partial \theta^{[3]}} \\
b^{[3]} := b^{[3]} - lr \times \frac{\partial l}{\partial b^{[3]}} \\
\theta^{[2]} := \theta^{[2]} - lr \times \frac{\partial l}{\partial \theta^{[2]}} \\
b^{[2]} := b^{[2]} - lr \times \frac{\partial l}{\partial b^{[2]}} \\
\theta^{[1]} := \theta^{[1]} - lr \times \frac{\partial l}{\partial \theta^{[1]}} \\
b^{[1]} := b^{[1]} - lr \times \frac{\partial l}{\partial b^{[1]}}
\end{align*} where \(lr\) is the learning rate. It decides the step size
we want to take in the direction of the negative gradient.

TODO: Implement the update\_weights function in NN.py with
use\_adam=False.

Hint: Refer to this
\href{https://static.us.edusercontent.com/files/gznuqr6aWHD8dPhiusG2TG53}{guide}
for more detail on the backward pass.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}update\PYZus{}weights}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}update\PYZus{}weights}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_update\_weights passed!
    \end{Verbatim}

    \paragraph{1.1.9 Update Weights with Adam {[}Required for grad, Bonus
for
undergrad{]}}\label{update-weights-with-adam-required-for-grad-bonus-for-undergrad}

    Gradient descent does a generally good job of facilitating the
convergence of the model's parameters to minimize the loss function.
However, the process of doing so can be slow and/or noisy.

\textbf{Adam (Adaptive Moment Estimation)} is an advanced optimization
algorithm that combines the benefits of two other popular optimization
techniques: RMSprop and momentum. Introduced by Kingma and Ba in 2014,
Adam has become one of the most widely used optimization algorithms in
deep learning due to its efficiency and effectiveness across a wide
range of problems. It adapts the learning update for each parameter
individually, making it particularly well-suited for problems with
sparse gradients or noisy data.

As a reminder, vanilla gradient descent applies the following update
function to the parameters:

\[
\begin{equation}
\theta_{t+1} = \theta_t - \alpha \nabla f(\theta_t)
\end{equation}
\]

where \(\theta_t\) represents the parameters at time \(t\), \(\alpha\)
represents the learning rate, and \(f\) is the loss function.

Adam proposes the following tweak to our parameter update function:

Firstly, it defines two variables \(M_t\) and \(V_t\), every variable in
the layer would need these two to update in for each iteration.

\[
\begin{align*}
M_t &= \beta_1 M_{t-1} + (1-\beta_1) \nabla f(\theta_t) \\
V_t &= \beta_2 V_{t-1} +(1- \beta_2) \nabla f(\theta_t)^2\\
\end{align*}
\]

Here: - t is a single parameter in our network (e.g.~theta3 or bias1) -
\textbf{\(M_t\) (First Moment)} - This tracks the exponentially weighted
moving average of the gradients of parameter t. It's similar to momentum
and helps the optimization continue moving in consistent directions.
Essentially, it's an estimate of the mean of the gradients. - Intuition:
Think of it as a ball rolling down a hill - it builds up momentum in
promising directions and helps overcome small obstacles (local minima)
along the way. It remembers where we've been going and helps us stay on
course. - \textbf{\(V_t\) (Second Moment)} - This tracks the
exponentially weighted moving average of the squared gradients of
parameter t. It captures the variance of gradients, which helps adapt
the learning update for each parameter. - Intuition: Imagine driving
through varied terrain - you'd slow down on rough roads (high gradient
variance) and speed up on smooth highways (low gradient variance).
\(V_t\)\hspace{0pt} provides this terrain-specific speed control for
each parameter. - \textbf{\(\beta_1\) and \(\beta_2\)}: These
hyperparameters control how much the algorithm relies on information
from new gradient vs.~previously calculated \(M_t\) or \(V_t\) for the
parameter t: - \(\beta_1\) (typically 0.9) controls the decay rate of
the moving average of the gradient - \(\beta_2\) (typically 0.999)
controls the decay rate of the moving average of the squared gradient -
The values show we trust our history (90\% for direction, 99.9\% for
variance) more than any single new piece of information. This makes Adam
robust to noisy gradients in a single batch.

Before we use these moment estimates to update our variables, they need
to be standardized to correct for initialization bias:

\[
\begin{align*}
\hat{M_t} &= \frac{M_t}{1-(\beta_1)^t} \\
\hat{V_t} &= \frac{V_t}{1-(\beta_2)^t}\\
\end{align*}
\]

This is also called bias correction. It's useful because the initial
estimates are usually not reliable. These correction terms prevent the
early updates from being too small by compensating for the fact that
\(M_0\) and \(V_0\) start at zero.

Now we can have our updating formula for Adam:

\[
\theta_{t+1} = \theta_t - \alpha \frac{\hat{M_t}}{\sqrt{\hat{V_t}} + \epsilon}
\]

\(\epsilon\) is a constant equal to \(10^{-8}\) to avoid numerical error
in the denominator.

Overall, Adam works really well because we maintain \(M_t\) and \(V_t\)
for every parameter. - Parameters with clear, consistent gradients get
larger updates (high \(M_t\), low \(V_t\)) - Parameters with noisy or
sparse gradients get smaller, more careful updates (high \(V_t\), low
\(M_t\)) - The overall direction benefits from momentum, smoothing the
optimization path - Each parameter gets its own custom learning rate,
automatically tuned based on its gradient history

Here is an additional resource for learning more about Adam
optimization: -
\href{https://www.youtube.com/watch?v=MD2fYip6QsQ&t=1034s}{Who's Adam
and What's He Optimizing? \textbar{} Deep Dive into Optimizers for
Machine Learning!}

TODO: Implement the update\_weights function in NN.py with
use\_adam=True.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}update\PYZus{}weights\PYZus{}with\PYZus{}adam}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}update\PYZus{}weights\PYZus{}with\PYZus{}adam}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_update\_weights\_with\_adam passed!
    \end{Verbatim}

    \paragraph{1.1.10 Backward Pass}\label{backward-pass}

    Now, we can combine the two functions \texttt{compute\ gradients} and
\texttt{update\_weights} to perform a complete backward pass through the
network.

TODO: Implement the backward function in NN.py.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}backward}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}backward}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_backward passed!
    \end{Verbatim}

    \paragraph{1.1.11 Gradient Descent}\label{gradient-descent}

    TODO: Implement the gradient\_descent function in NN.py.

This method is also commonly known as batch gradient descent. Look at
the function documentation in gradient\_descent for guidance. You may
test your implementation of the gradient descent function contained in
\textbf{NN.py} in the cell below. See
\hyperref[using_local_tests]{Using the Local Tests} for more details.

Below, we test the first three iterations as a sanity check. For the
final Gradescope evaluation, your implementation will be trained for a
larger number of iterations to fully optimize the network. To achieve
full credit, your network must attain a final cross entropy loss of 1 or
lower.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}gradient\PYZus{}descent}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}gradient\PYZus{}descent}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.086384
Loss after iteration 1: 1.086313
Loss after iteration 2: 1.086242

Your GD losses works within the expected range: True
    \end{Verbatim}

    \paragraph{1.1.12 Mini-batch Gradient
Descent}\label{mini-batch-gradient-descent}

    TODO: Implement the minibatch\_gradient\_descent function in NN.py.

Look at the function documentation in gradient\_descent for guidance.
You may test your implementation of the mini-batch gradient descent
function contained in \textbf{NN.py} in the cell below. See
\hyperref[using_local_tests]{Using the Local Tests} for more details.

Below, we test the first three iterations as a sanity check. For the
final Gradescope evaluation, your implementation will be trained for a
larger number of iterations to fully optimize the network. To achieve
full credit, your network must attain a final cross entropy loss of 1 or
lower.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}minibatch\PYZus{}gradient\PYZus{}descent}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}minibatch\PYZus{}gradient\PYZus{}descent}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.111743
Loss after iteration 1: 1.108553
Loss after iteration 2: 1.084159
Your batch\_y works within the expected range: True

Your mini-batch GD losses works within the expected range: True
    \end{Verbatim}

    \paragraph{1.1.13 Gradient Descent with Adam {[}Required for grad, Bonus
for
undergrad{]}}\label{gradient-descent-with-adam-required-for-grad-bonus-for-undergrad}

    You may test your implementation of the GD function with adam contained
in \textbf{NN.py} in the cell below. See
\hyperref[using_local_tests]{Using the Local Tests} for more details.
Revisit your implementation for update\_weights.

Below, we test the first three iterations as a sanity check. For the
final Gradescope evaluation, your implementation will be trained for a
larger number of iterations to fully optimize the network. To achieve
full credit, your network must attain a final cross entropy loss of 1 or
lower.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}gradient\PYZus{}descent\PYZus{}with\PYZus{}adam}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}gradient\PYZus{}descent\PYZus{}with\PYZus{}adam}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.086384
Loss after iteration 1: 1.077445
Loss after iteration 2: 1.068520

Your GD losses works within the expected range: True
    \end{Verbatim}

    \paragraph{1.1.14 Mini-batch Gradient Descent with Adam {[}Required for
grad, Bonus for
undergrad{]}}\label{mini-batch-gradient-descent-with-adam-required-for-grad-bonus-for-undergrad}

    You may test your implementation of the mini-batch gradient descent
function contained in \textbf{NN.py} when use\_adam=True in the cell
below. See \hyperref[using_local_tests]{Using the Local Tests} for more
details.

Below, we test the first three iterations as a sanity check. For the
final Gradescope evaluation, your implementation will be trained for a
larger number of iterations to fully optimize the network. To achieve
full credit, your network must attain a final cross entropy loss of 1 or
lower.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestNN}

\PY{n}{TestNN}\PY{p}{(}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}minibatch\PYZus{}gradient\PYZus{}descent\PYZus{}with\PYZus{}adam}\PY{l+s+s2}{\PYZdq{}}
\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}minibatch\PYZus{}gradient\PYZus{}descent\PYZus{}with\PYZus{}adam}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.079837
Loss after iteration 1: 1.097294
Loss after iteration 2: 1.078121

Your GD losses works within the expected range: True
    \end{Verbatim}

    \subsubsection{\texorpdfstring{1.2 Loss plot, cross-entropy (CE) value,
and Learning Rate with Gradient Descent {[}9.5pts{]} {\textbf{{[}P{]}}}
\textbar{}
{\textbf{{[}W{]}}}}{1.2 Loss plot, cross-entropy (CE) value, and Learning Rate with Gradient Descent {[}9.5pts{]} {[}P{]} \textbar{} {[}W{]}}}\label{loss-plot-cross-entropy-ce-value-and-learning-rate-with-gradient-descent-9.5pts-p-w}

    \paragraph{1.2.1 Loss plot and cross-entropy(CE) value with Gradient
Descent
{[}7.5pts{]}}\label{loss-plot-and-cross-entropyce-value-with-gradient-descent-7.5pts}

    Now, you can fully train your neural network implementation with
gradient descent. The following cells will plot the loss vs epoch graph
and calculate the final test cross-entropy(CE).

You can test and debug your network here, but your implementation will
be tested on gradescope so there is no partial credit for notebook
output.

To achieve full credit on gradescope: 1. Your loss trajectory should be
smooth, decreasing and similar to expected trajectory (check expected
output PDF) (2.5 pts) 2. Your final cross entropy loss must be 0.8 or
lower (2pts) 3. The diagonal entries in your confusion matrix must be
within 0.15 of the expected values (check expected output PDF) (2.5 pts)

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{NN}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{NeuralNet}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{ConfusionMatrixDisplay}

\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}housing\PYZus{}dataset}\PY{p}{(}\PY{p}{)}

\PY{n}{nn} \PY{o}{=} \PY{n}{NeuralNet}\PY{p}{(}
    \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{use\PYZus{}adam}\PY{o}{=}\PY{k+kc}{False}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} initialize neural net class}
\PY{n}{nn}\PY{o}{.}\PY{n}{gradient\PYZus{}descent}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n+nb}{iter}\PY{o}{=}\PY{l+m+mi}{60000}\PY{p}{)}  \PY{c+c1}{\PYZsh{} train}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.086384
Loss after iteration 1000: 1.001952
Loss after iteration 2000: 0.846899
Loss after iteration 3000: 0.718109
Loss after iteration 4000: 0.649426
Loss after iteration 5000: 0.607674
Loss after iteration 6000: 0.580241
Loss after iteration 7000: 0.561059
Loss after iteration 8000: 0.547331
Loss after iteration 9000: 0.537094
Loss after iteration 10000: 0.529029
Loss after iteration 11000: 0.522520
Loss after iteration 12000: 0.517104
Loss after iteration 13000: 0.512428
Loss after iteration 14000: 0.508310
Loss after iteration 15000: 0.504628
Loss after iteration 16000: 0.501325
Loss after iteration 17000: 0.498342
Loss after iteration 18000: 0.495574
Loss after iteration 19000: 0.492921
Loss after iteration 20000: 0.490341
Loss after iteration 21000: 0.487806
Loss after iteration 22000: 0.485304
Loss after iteration 23000: 0.482841
Loss after iteration 24000: 0.480429
Loss after iteration 25000: 0.478076
Loss after iteration 26000: 0.475778
Loss after iteration 27000: 0.473541
Loss after iteration 28000: 0.471367
Loss after iteration 29000: 0.469261
Loss after iteration 30000: 0.467202
Loss after iteration 31000: 0.465174
Loss after iteration 32000: 0.463173
Loss after iteration 33000: 0.461193
Loss after iteration 34000: 0.459237
Loss after iteration 35000: 0.457314
Loss after iteration 36000: 0.455438
Loss after iteration 37000: 0.453604
Loss after iteration 38000: 0.451796
Loss after iteration 39000: 0.450005
Loss after iteration 40000: 0.448192
Loss after iteration 41000: 0.446410
Loss after iteration 42000: 0.444626
Loss after iteration 43000: 0.442824
Loss after iteration 44000: 0.441061
Loss after iteration 45000: 0.439332
Loss after iteration 46000: 0.437641
Loss after iteration 47000: 0.435985
Loss after iteration 48000: 0.434350
Loss after iteration 49000: 0.432724
Loss after iteration 50000: 0.431106
Loss after iteration 51000: 0.429496
Loss after iteration 52000: 0.427883
Loss after iteration 53000: 0.426264
Loss after iteration 54000: 0.424637
Loss after iteration 55000: 0.422997
Loss after iteration 56000: 0.421348
Loss after iteration 57000: 0.419686
Loss after iteration 58000: 0.418015
Loss after iteration 59000: 0.416338
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot confusion matrix}
\PY{n}{y\PYZus{}true} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
\PY{n}{display\PYZus{}labels} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{low}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{med}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{high}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{ConfusionMatrixDisplay}\PY{o}{.}\PY{n}{from\PYZus{}predictions}\PY{p}{(}
    \PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{normalize}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{true}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{display\PYZus{}labels}\PY{o}{=}\PY{n}{display\PYZus{}labels}
\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_81_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot training loss}
\PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{loss}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Epoch (thousands)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_82_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Total loss}
\PY{n}{y\PYZus{}hat} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{forward}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Cross entropy loss:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n+nb}{round}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{cross\PYZus{}entropy\PYZus{}loss}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}hat}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Cross entropy loss: 0.681
    \end{Verbatim}

    \paragraph{1.2.2 Learning Rate with Gradient Descent
{[}2pts{]}}\label{learning-rate-with-gradient-descent-2pts}

    Here we have provided three different learning rates to use for
training. Run the plots for each learning rate and describe each plot.
Which learning rate works best? Explain how you know.

{\textbf{{[}W{]}} Please assign all pages containing your answer to the
question. You should assign both your evidence generated from code
cells, including the below plots or any you may add. You should also
assign any markdown cells containing your ultimate choice and
justification.}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{NN}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{NeuralNet}

\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}housing\PYZus{}dataset}\PY{p}{(}\PY{p}{)}

\PY{n}{nn} \PY{o}{=} \PY{n}{NeuralNet}\PY{p}{(}
    \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{use\PYZus{}adam}\PY{o}{=}\PY{k+kc}{False}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} initialize neural net class}
\PY{n}{nn}\PY{o}{.}\PY{n}{gradient\PYZus{}descent}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n+nb}{iter}\PY{o}{=}\PY{l+m+mi}{60000}\PY{p}{)}  \PY{c+c1}{\PYZsh{} train}

\PY{c+c1}{\PYZsh{} Plot training loss}
\PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{loss}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Epoch (thousands)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.086384
Loss after iteration 1000: 0.529056
Loss after iteration 2000: 0.509310
Loss after iteration 3000: 0.485269
Loss after iteration 4000: 0.465143
Loss after iteration 5000: 0.448164
Loss after iteration 6000: 0.434512
Loss after iteration 7000: 0.422164
Loss after iteration 8000: 0.413500
Loss after iteration 9000: 0.397260
Loss after iteration 10000: 0.385149
Loss after iteration 11000: 0.373969
Loss after iteration 12000: 0.364383
Loss after iteration 13000: 0.358991
Loss after iteration 14000: 0.341489
Loss after iteration 15000: 0.336735
Loss after iteration 16000: 0.330647
Loss after iteration 17000: 0.309012
Loss after iteration 18000: 0.310486
Loss after iteration 19000: 0.292806
Loss after iteration 20000: 0.280467
Loss after iteration 21000: 0.275612
Loss after iteration 22000: 0.269508
Loss after iteration 23000: 0.308830
Loss after iteration 24000: 0.242329
Loss after iteration 25000: 0.301847
Loss after iteration 26000: 0.274905
Loss after iteration 27000: 0.212884
Loss after iteration 28000: 0.207031
Loss after iteration 29000: 0.202791
Loss after iteration 30000: 0.206914
Loss after iteration 31000: 0.188975
Loss after iteration 32000: 0.193483
Loss after iteration 33000: 0.179602
Loss after iteration 34000: 0.159240
Loss after iteration 35000: 0.174250
Loss after iteration 36000: 0.146227
Loss after iteration 37000: 0.180497
Loss after iteration 38000: 0.132637
Loss after iteration 39000: 0.130191
Loss after iteration 40000: 0.121921
Loss after iteration 41000: 0.117122
Loss after iteration 42000: 0.112762
Loss after iteration 43000: 0.108785
Loss after iteration 44000: 0.105160
Loss after iteration 45000: 0.101996
Loss after iteration 46000: 0.098016
Loss after iteration 47000: 0.095523
Loss after iteration 48000: 0.091719
Loss after iteration 49000: 0.089903
Loss after iteration 50000: 0.085827
Loss after iteration 51000: 0.082544
Loss after iteration 52000: 0.080607
Loss after iteration 53000: 0.077049
Loss after iteration 54000: 0.073792
Loss after iteration 55000: 0.071853
Loss after iteration 56000: 0.068696
Loss after iteration 57000: 0.069374
Loss after iteration 58000: 0.063761
Loss after iteration 59000: 0.062024
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_86_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}housing\PYZus{}dataset}\PY{p}{(}\PY{p}{)}

\PY{n}{nn} \PY{o}{=} \PY{n}{NeuralNet}\PY{p}{(}
    \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.03}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{use\PYZus{}adam}\PY{o}{=}\PY{k+kc}{False}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} initialize neural net class}
\PY{n}{nn}\PY{o}{.}\PY{n}{gradient\PYZus{}descent}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n+nb}{iter}\PY{o}{=}\PY{l+m+mi}{60000}\PY{p}{)}  \PY{c+c1}{\PYZsh{} train}

\PY{c+c1}{\PYZsh{} Plot training loss}
\PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{loss}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Epoch (thousands)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.086384
Loss after iteration 1000: 0.718204
Loss after iteration 2000: 0.580262
Loss after iteration 3000: 0.537101
Loss after iteration 4000: 0.517108
Loss after iteration 5000: 0.504630
Loss after iteration 6000: 0.495575
Loss after iteration 7000: 0.487807
Loss after iteration 8000: 0.480430
Loss after iteration 9000: 0.473541
Loss after iteration 10000: 0.467201
Loss after iteration 11000: 0.461192
Loss after iteration 12000: 0.455436
Loss after iteration 13000: 0.450003
Loss after iteration 14000: 0.444614
Loss after iteration 15000: 0.439320
Loss after iteration 16000: 0.434343
Loss after iteration 17000: 0.429491
Loss after iteration 18000: 0.424633
Loss after iteration 19000: 0.419684
Loss after iteration 20000: 0.414647
Loss after iteration 21000: 0.409434
Loss after iteration 22000: 0.403911
Loss after iteration 23000: 0.398313
Loss after iteration 24000: 0.393064
Loss after iteration 25000: 0.387935
Loss after iteration 26000: 0.382836
Loss after iteration 27000: 0.377706
Loss after iteration 28000: 0.372494
Loss after iteration 29000: 0.367088
Loss after iteration 30000: 0.361588
Loss after iteration 31000: 0.356047
Loss after iteration 32000: 0.350357
Loss after iteration 33000: 0.344705
Loss after iteration 34000: 0.339192
Loss after iteration 35000: 0.333826
Loss after iteration 36000: 0.328670
Loss after iteration 37000: 0.323721
Loss after iteration 38000: 0.318972
Loss after iteration 39000: 0.314381
Loss after iteration 40000: 0.309958
Loss after iteration 41000: 0.311591
Loss after iteration 42000: 0.308765
Loss after iteration 43000: 0.305905
Loss after iteration 44000: 0.302806
Loss after iteration 45000: 0.300045
Loss after iteration 46000: 0.296678
Loss after iteration 47000: 0.293210
Loss after iteration 48000: 0.289941
Loss after iteration 49000: 0.283736
Loss after iteration 50000: 0.279455
Loss after iteration 51000: 0.274613
Loss after iteration 52000: 0.269466
Loss after iteration 53000: 0.263483
Loss after iteration 54000: 0.257939
Loss after iteration 55000: 0.253394
Loss after iteration 56000: 0.249227
Loss after iteration 57000: 0.245576
Loss after iteration 58000: 0.242489
Loss after iteration 59000: 0.238546
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_87_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}housing\PYZus{}dataset}\PY{p}{(}\PY{p}{)}

\PY{n}{nn} \PY{o}{=} \PY{n}{NeuralNet}\PY{p}{(}
    \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.0002}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{use\PYZus{}adam}\PY{o}{=}\PY{k+kc}{False}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} initialize neural net class}
\PY{n}{nn}\PY{o}{.}\PY{n}{gradient\PYZus{}descent}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n+nb}{iter}\PY{o}{=}\PY{l+m+mi}{60000}\PY{p}{)}  \PY{c+c1}{\PYZsh{} train}

\PY{c+c1}{\PYZsh{} Plot training loss}
\PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{loss}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Epoch (thousands)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.086384
Loss after iteration 1000: 1.084990
Loss after iteration 2000: 1.083646
Loss after iteration 3000: 1.082339
Loss after iteration 4000: 1.081052
Loss after iteration 5000: 1.079777
Loss after iteration 6000: 1.078503
Loss after iteration 7000: 1.077224
Loss after iteration 8000: 1.075934
Loss after iteration 9000: 1.074627
Loss after iteration 10000: 1.073300
Loss after iteration 11000: 1.071951
Loss after iteration 12000: 1.070577
Loss after iteration 13000: 1.069179
Loss after iteration 14000: 1.067754
Loss after iteration 15000: 1.066303
Loss after iteration 16000: 1.064832
Loss after iteration 17000: 1.063344
Loss after iteration 18000: 1.061845
Loss after iteration 19000: 1.060333
Loss after iteration 20000: 1.058808
Loss after iteration 21000: 1.057272
Loss after iteration 22000: 1.055721
Loss after iteration 23000: 1.054153
Loss after iteration 24000: 1.052565
Loss after iteration 25000: 1.050955
Loss after iteration 26000: 1.049321
Loss after iteration 27000: 1.047659
Loss after iteration 28000: 1.045967
Loss after iteration 29000: 1.044243
Loss after iteration 30000: 1.042488
Loss after iteration 31000: 1.040699
Loss after iteration 32000: 1.038880
Loss after iteration 33000: 1.037035
Loss after iteration 34000: 1.035164
Loss after iteration 35000: 1.033271
Loss after iteration 36000: 1.031357
Loss after iteration 37000: 1.029424
Loss after iteration 38000: 1.027474
Loss after iteration 39000: 1.025504
Loss after iteration 40000: 1.023512
Loss after iteration 41000: 1.021497
Loss after iteration 42000: 1.019455
Loss after iteration 43000: 1.017383
Loss after iteration 44000: 1.015278
Loss after iteration 45000: 1.013140
Loss after iteration 46000: 1.010967
Loss after iteration 47000: 1.008758
Loss after iteration 48000: 1.006511
Loss after iteration 49000: 1.004227
Loss after iteration 50000: 1.001904
Loss after iteration 51000: 0.999541
Loss after iteration 52000: 0.997137
Loss after iteration 53000: 0.994691
Loss after iteration 54000: 0.992204
Loss after iteration 55000: 0.989675
Loss after iteration 56000: 0.987103
Loss after iteration 57000: 0.984489
Loss after iteration 58000: 0.981835
Loss after iteration 59000: 0.979140
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_88_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

The learning rate \texttt{lr=0.1} works best. Over the same number of
iterations, it achieves the lowest training loss of \textasciitilde0.06,
much less than \textasciitilde0.24 and \textasciitilde0.98 reached by
the other learning rates. It also learned much faster than the other
two.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \subsubsection{\texorpdfstring{1.3 Loss plot and CE value for Mini-batch
GD {[}7.5pts{]}
{\textbf{{[}P{]}}}}{1.3 Loss plot and CE value for Mini-batch GD {[}7.5pts{]} {[}P{]}}}\label{loss-plot-and-ce-value-for-mini-batch-gd-7.5pts-p}

    Train your neural network implementation with mini-batch gradient
descent and print out the loss at every 1000th iteration (starting at
iteration 0). The following cells will plot the loss vs epoch graph and
calculate the final test CE.

You can test and debug your network here, but your implementation will
be tested on gradescope so there is no partial credit for notebook
output.

To achieve full credit on gradescope: 1. Your loss trajectory should be
decreasing and similar to expected trajectory (2.5 pts) 2. Your final
cross entropy loss must be within 0.7 of the expected loss (2.5 pts) 3.
The diagonal entries in your confusion matrix must be within 0.15 of the
expected values (2.5 pts)

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{NN}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{NeuralNet}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{ConfusionMatrixDisplay}\PY{p}{,} \PY{n}{confusion\PYZus{}matrix}

\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}housing\PYZus{}dataset}\PY{p}{(}\PY{p}{)}

\PY{n}{nn} \PY{o}{=} \PY{n}{NeuralNet}\PY{p}{(}
    \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{use\PYZus{}adam}\PY{o}{=}\PY{k+kc}{False}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} initialize neural net class}
\PY{n}{nn}\PY{o}{.}\PY{n}{minibatch\PYZus{}gradient\PYZus{}descent}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n+nb}{iter}\PY{o}{=}\PY{l+m+mi}{60000}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.091859
Loss after iteration 1000: 1.035899
Loss after iteration 2000: 0.847171
Loss after iteration 3000: 0.741736
Loss after iteration 4000: 0.773022
Loss after iteration 5000: 0.565779
Loss after iteration 6000: 0.582815
Loss after iteration 7000: 0.587042
Loss after iteration 8000: 0.466858
Loss after iteration 9000: 0.536166
Loss after iteration 10000: 0.587051
Loss after iteration 11000: 0.480393
Loss after iteration 12000: 0.489757
Loss after iteration 13000: 0.617539
Loss after iteration 14000: 0.426187
Loss after iteration 15000: 0.510418
Loss after iteration 16000: 0.512826
Loss after iteration 17000: 0.465207
Loss after iteration 18000: 0.492669
Loss after iteration 19000: 0.609935
Loss after iteration 20000: 0.336917
Loss after iteration 21000: 0.489244
Loss after iteration 22000: 0.584403
Loss after iteration 23000: 0.367593
Loss after iteration 24000: 0.473196
Loss after iteration 25000: 0.550124
Loss after iteration 26000: 0.349599
Loss after iteration 27000: 0.464375
Loss after iteration 28000: 0.570501
Loss after iteration 29000: 0.381022
Loss after iteration 30000: 0.471606
Loss after iteration 31000: 0.569234
Loss after iteration 32000: 0.363034
Loss after iteration 33000: 0.489637
Loss after iteration 34000: 0.531827
Loss after iteration 35000: 0.352604
Loss after iteration 36000: 0.507195
Loss after iteration 37000: 0.546935
Loss after iteration 38000: 0.348872
Loss after iteration 39000: 0.432399
Loss after iteration 40000: 0.542698
Loss after iteration 41000: 0.335282
Loss after iteration 42000: 0.419321
Loss after iteration 43000: 0.516011
Loss after iteration 44000: 0.338062
Loss after iteration 45000: 0.463816
Loss after iteration 46000: 0.562512
Loss after iteration 47000: 0.340467
Loss after iteration 48000: 0.426473
Loss after iteration 49000: 0.528113
Loss after iteration 50000: 0.326665
Loss after iteration 51000: 0.475154
Loss after iteration 52000: 0.535218
Loss after iteration 53000: 0.376442
Loss after iteration 54000: 0.454066
Loss after iteration 55000: 0.529333
Loss after iteration 56000: 0.313504
Loss after iteration 57000: 0.483299
Loss after iteration 58000: 0.561374
Loss after iteration 59000: 0.320788
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot training loss}
\PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{loss}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Iteration (1000)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_93_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot confusion matrix}
\PY{n}{y\PYZus{}true} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
\PY{n}{display\PYZus{}labels} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{low}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{med}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{high}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{ConfusionMatrixDisplay}\PY{o}{.}\PY{n}{from\PYZus{}predictions}\PY{p}{(}
    \PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{normalize}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{true}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{display\PYZus{}labels}\PY{o}{=}\PY{n}{display\PYZus{}labels}
\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_94_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Total loss}
\PY{n}{y\PYZus{}hat} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{forward}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Cross entropy loss:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n+nb}{round}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{cross\PYZus{}entropy\PYZus{}loss}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}hat}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Cross entropy loss: 0.712
    \end{Verbatim}

    \subsubsection{\texorpdfstring{1.4 Loss plot and CE value for Gradient
Descent with Adam {[}7.5pts Grad / 1\% Bonus for Undergrad{]}
{\textbf{{[}P{]}}}}{1.4 Loss plot and CE value for Gradient Descent with Adam {[}7.5pts Grad / 1\% Bonus for Undergrad{]} {[}P{]}}}\label{loss-plot-and-ce-value-for-gradient-descent-with-adam-7.5pts-grad-1-bonus-for-undergrad-p}

    Train your neural net implementation using gradient descent with Adam
and print out the loss at every 1000th iteration (starting at iteration
0). The following cells will plot the loss vs epoch graph and calculate
the final test CE.

To achieve full credit on gradescope: 1. Your loss trajectory should be
decreasing and similar to expected trajectory (2.5 pts) 2. Your final
cross entropy loss must be within 0.7 of the expected loss (2.5 pts) 3.
The diagonal entries in your confusion matrix must be within 0.15 of the
expected values (2.5 pts)

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{NN}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{NeuralNet}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{ConfusionMatrixDisplay}\PY{p}{,} \PY{n}{confusion\PYZus{}matrix}

\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}housing\PYZus{}dataset}\PY{p}{(}\PY{p}{)}

\PY{n}{nn} \PY{o}{=} \PY{n}{NeuralNet}\PY{p}{(}
    \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.0001}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{use\PYZus{}adam}\PY{o}{=}\PY{k+kc}{True}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} initialize neural net class}
\PY{n}{nn}\PY{o}{.}\PY{n}{gradient\PYZus{}descent}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n+nb}{iter}\PY{o}{=}\PY{l+m+mi}{60000}\PY{p}{)}  \PY{c+c1}{\PYZsh{} train}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.092085
Loss after iteration 1000: 0.994819
Loss after iteration 2000: 0.818885
Loss after iteration 3000: 0.708302
Loss after iteration 4000: 0.657461
Loss after iteration 5000: 0.611148
Loss after iteration 6000: 0.585753
Loss after iteration 7000: 0.561844
Loss after iteration 8000: 0.548353
Loss after iteration 9000: 0.525937
Loss after iteration 10000: 0.516159
Loss after iteration 11000: 0.517531
Loss after iteration 12000: 0.500480
Loss after iteration 13000: 0.505991
Loss after iteration 14000: 0.509984
Loss after iteration 15000: 0.500153
Loss after iteration 16000: 0.495247
Loss after iteration 17000: 0.497214
Loss after iteration 18000: 0.497009
Loss after iteration 19000: 0.498928
Loss after iteration 20000: 0.486947
Loss after iteration 21000: 0.502284
Loss after iteration 22000: 0.480663
Loss after iteration 23000: 0.481239
Loss after iteration 24000: 0.475030
Loss after iteration 25000: 0.491100
Loss after iteration 26000: 0.495675
Loss after iteration 27000: 0.463680
Loss after iteration 28000: 0.468387
Loss after iteration 29000: 0.484296
Loss after iteration 30000: 0.476243
Loss after iteration 31000: 0.481268
Loss after iteration 32000: 0.469781
Loss after iteration 33000: 0.464685
Loss after iteration 34000: 0.476446
Loss after iteration 35000: 0.457027
Loss after iteration 36000: 0.466227
Loss after iteration 37000: 0.478422
Loss after iteration 38000: 0.464461
Loss after iteration 39000: 0.472205
Loss after iteration 40000: 0.462635
Loss after iteration 41000: 0.461205
Loss after iteration 42000: 0.443126
Loss after iteration 43000: 0.463238
Loss after iteration 44000: 0.467495
Loss after iteration 45000: 0.463566
Loss after iteration 46000: 0.434615
Loss after iteration 47000: 0.462420
Loss after iteration 48000: 0.450356
Loss after iteration 49000: 0.450394
Loss after iteration 50000: 0.443737
Loss after iteration 51000: 0.448532
Loss after iteration 52000: 0.441352
Loss after iteration 53000: 0.438072
Loss after iteration 54000: 0.444127
Loss after iteration 55000: 0.438280
Loss after iteration 56000: 0.455997
Loss after iteration 57000: 0.444804
Loss after iteration 58000: 0.441443
Loss after iteration 59000: 0.431706
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot training loss}
\PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{loss}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Iteration (1000)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_99_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{32}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot confusion matrix}
\PY{n}{y\PYZus{}true} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
\PY{n}{display\PYZus{}labels} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{low}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{med}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{high}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{ConfusionMatrixDisplay}\PY{o}{.}\PY{n}{from\PYZus{}predictions}\PY{p}{(}
    \PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{normalize}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{true}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{display\PYZus{}labels}\PY{o}{=}\PY{n}{display\PYZus{}labels}
\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_100_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Total loss}
\PY{n}{y\PYZus{}hat} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{forward}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Cross entropy loss:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n+nb}{round}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{cross\PYZus{}entropy\PYZus{}loss}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}hat}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Cross entropy loss: 0.741
    \end{Verbatim}

    \subsubsection{\texorpdfstring{1.5 Loss plot and CE value for Mini-batch
GD with Adam {[}7.5pts Grad / 1\% Bonus for Undergrad{]}
{\textbf{{[}P{]}}}}{1.5 Loss plot and CE value for Mini-batch GD with Adam {[}7.5pts Grad / 1\% Bonus for Undergrad{]} {[}P{]}}}\label{loss-plot-and-ce-value-for-mini-batch-gd-with-adam-7.5pts-grad-1-bonus-for-undergrad-p}

    Now, you can train your neural network implementation with mini-batch
gradient descent with Adam and print out the loss at every 1000th
iteration (starting at iteration 0). The following cells will plot the
loss vs epoch graph and calculate the final test CE.

To achieve full credit on gradescope: 1. Your loss trajectory should be
decreasing and similar to expected trajectory (2.5 pts) 2. Your final
cross entropy loss must be within 0.7 of the expected loss (2.5 pts) 3.
The diagonal entries in your confusion matrix must be within 0.15 of the
expected values (2.5 pts)

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{34}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{NN}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{NeuralNet}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{ConfusionMatrixDisplay}\PY{p}{,} \PY{n}{confusion\PYZus{}matrix}

\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}housing\PYZus{}dataset}\PY{p}{(}\PY{p}{)}

\PY{n}{nn} \PY{o}{=} \PY{n}{NeuralNet}\PY{p}{(}
    \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.0001}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{use\PYZus{}adam}\PY{o}{=}\PY{k+kc}{True}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} initialize neural net class}
\PY{n}{nn}\PY{o}{.}\PY{n}{minibatch\PYZus{}gradient\PYZus{}descent}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n+nb}{iter}\PY{o}{=}\PY{l+m+mi}{60000}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loss after iteration 0: 1.091859
Loss after iteration 1000: 1.030364
Loss after iteration 2000: 0.847108
Loss after iteration 3000: 0.768244
Loss after iteration 4000: 0.762525
Loss after iteration 5000: 0.597977
Loss after iteration 6000: 0.620159
Loss after iteration 7000: 0.645412
Loss after iteration 8000: 0.516455
Loss after iteration 9000: 0.581680
Loss after iteration 10000: 0.608523
Loss after iteration 11000: 0.501214
Loss after iteration 12000: 0.547743
Loss after iteration 13000: 0.673327
Loss after iteration 14000: 0.461862
Loss after iteration 15000: 0.527386
Loss after iteration 16000: 0.607045
Loss after iteration 17000: 0.458089
Loss after iteration 18000: 0.521128
Loss after iteration 19000: 0.619692
Loss after iteration 20000: 0.375154
Loss after iteration 21000: 0.479561
Loss after iteration 22000: 0.626976
Loss after iteration 23000: 0.383667
Loss after iteration 24000: 0.476830
Loss after iteration 25000: 0.575961
Loss after iteration 26000: 0.353128
Loss after iteration 27000: 0.482767
Loss after iteration 28000: 0.600986
Loss after iteration 29000: 0.393712
Loss after iteration 30000: 0.449460
Loss after iteration 31000: 0.568763
Loss after iteration 32000: 0.349636
Loss after iteration 33000: 0.496331
Loss after iteration 34000: 0.577693
Loss after iteration 35000: 0.306311
Loss after iteration 36000: 0.533231
Loss after iteration 37000: 0.593978
Loss after iteration 38000: 0.355743
Loss after iteration 39000: 0.466800
Loss after iteration 40000: 0.574201
Loss after iteration 41000: 0.344580
Loss after iteration 42000: 0.439001
Loss after iteration 43000: 0.570066
Loss after iteration 44000: 0.334673
Loss after iteration 45000: 0.474704
Loss after iteration 46000: 0.559083
Loss after iteration 47000: 0.329248
Loss after iteration 48000: 0.433405
Loss after iteration 49000: 0.576862
Loss after iteration 50000: 0.306490
Loss after iteration 51000: 0.481590
Loss after iteration 52000: 0.539496
Loss after iteration 53000: 0.353943
Loss after iteration 54000: 0.464240
Loss after iteration 55000: 0.556888
Loss after iteration 56000: 0.334425
Loss after iteration 57000: 0.452438
Loss after iteration 58000: 0.572210
Loss after iteration 59000: 0.314848
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{35}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot training loss}
\PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{loss}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Iteration (1000)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_105_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{36}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot confusion matrix}
\PY{n}{y\PYZus{}true} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
\PY{n}{display\PYZus{}labels} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{low}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{med}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{high}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{ConfusionMatrixDisplay}\PY{o}{.}\PY{n}{from\PYZus{}predictions}\PY{p}{(}
    \PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{normalize}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{true}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{display\PYZus{}labels}\PY{o}{=}\PY{n}{display\PYZus{}labels}
\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_106_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{37}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Total loss}
\PY{n}{y\PYZus{}hat} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{forward}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{use\PYZus{}dropout}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Cross entropy loss:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n+nb}{round}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{cross\PYZus{}entropy\PYZus{}loss}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}hat}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Cross entropy loss: 0.695
    \end{Verbatim}

    \subsection{\texorpdfstring{Q2: CNN Image Classification {[}26pts: 10pts
+ 16pts Grad / 2.4\% Bonus for Undergrad + 2.5\% Bonus for all{]}
{\textbf{{[}P{]}}} \textbar{}
{\textbf{{[}W{]}}}}{Q2: CNN Image Classification {[}26pts: 10pts + 16pts Grad / 2.4\% Bonus for Undergrad + 2.5\% Bonus for all{]} {[}P{]} \textbar{} {[}W{]}}}\label{q2-cnn-image-classification-26pts-10pts-16pts-grad-2.4-bonus-for-undergrad-2.5-bonus-for-all-p-w}

    \textbf{Pytorch Description}

\href{https://pytorch.org}{Pytorch} is a Machine Learning/Deep Learning
tensor library based on Python and Torch that uses dynamic computation
graphs. Pytorch is used for applications using GPUs and CPUs.

\textbf{Helpful Links}

The conda environment solver should have correctly installed the correct
software for your GPU. If it's being finicky,
\href{https://pytorch.org/get-started/locally/}{these directions} may be
helpful for a manual install.

Please also see
\href{https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html}{Pytorch
Quickstart Tutorial} to see how to load a data set, build a training
loop, and test the model. Another good resource for building CNNs using
Pytorch is
\href{https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/}{here}.

    \subsubsection{\texorpdfstring{2.1 CNN Image Classification {[}26pts:
10pts + 16pts Grad / 2.4\% Bonus for Undergrad{]}
{\textbf{{[}P{]}}}}{2.1 CNN Image Classification {[}26pts: 10pts + 16pts Grad / 2.4\% Bonus for Undergrad{]} {[}P{]}}}\label{cnn-image-classification-26pts-10pts-16pts-grad-2.4-bonus-for-undergrad-p}

    \paragraph{2.1.1 Load Brain Tumor MRI Dataset and Data
Augmentation}\label{load-brain-tumor-mri-dataset-and-data-augmentation}

    We use
\href{https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset}{Brain
Tumor MRI Dataset} to train our model. This dataset contains 7023 images
of human brain MRI images which are classified into 4 classes: glioma,
meningioma, no tumor, and pituitary. There are 5712 training images and
1311 test images. We adapt the code from
\href{https://github.com/masoudnick/Brain-Tumor-MRI-Classification}{Brain-Tumor-MRI-Classification}
to preprocess the downloaded Brain Tumor MRI Dataset.

Data augmentation is a technique to increase the diversity of your
training set by applying random (but realistic) transformations such as
image rotation and flipping the image around an axis. If the dataset in
a machine learning model is rich and sufficient, the model performs
better and more accurately. We will preprocess the training and testing
set, but only the training set will undergo augmentation.

Go through the
\href{https://pytorch.org/vision/master/transforms.html}{Pytorch
torchvision.transforms.v2 documentation} to see how to apply multiple
transformations at once.

In the cnn\_image\_transformations.py file, complete the following
functions to understand the common practices used for preprocessing and
augmenting the image data:

\begin{itemize}
\item
  create\_training\_transformations

  \begin{itemize}
  \item
    In this function, you are going to preprocess and augment training
    data.

    \begin{itemize}
    \item
      PREPROCESS: Convert the given PIL Images to Tensors
    \item
      AUGMENTATION: Apply Random Horizontal Flip and Random Rotation
    \end{itemize}
  \end{itemize}
\item
  create\_testing\_transformations

  \begin{itemize}
  \item
    In this function, you are going to only preprocess testing data.

    \begin{itemize}
    \tightlist
    \item
      PREPROCESS: Convert the given PIL Images to Tensors
    \end{itemize}
  \end{itemize}
\end{itemize}

Please note that the Gradescope only checks if expected preprocessing
layers are existent.

\textbf{References}

\href{https://pytorch.org/vision/main/generated/torchvision.transforms.v2.Compose.html}{v2.Compose()}

\href{https://pytorch.org/vision/main/generated/torchvision.transforms.v2.ToTensor.html}{v2.ToTensor()}
(Hint: Look at the warning)

\href{https://pytorch.org/vision/main/generated/torchvision.transforms.RandomHorizontalFlip.html}{v2.RandomHorizontalFlip()}

\href{https://pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomApply.html}{v2.RandomApply()}

\href{https://pytorch.org/vision/main/generated/torchvision.transforms.RandomRotation.html}{v2.RandomRotation()}

\href{https://pytorch.org/vision/master/transforms.html}{Article about
performance regarding transformations}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} Load data}
\PY{n}{classes} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{glioma}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{meningioma}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{notumor}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pituitary}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}mri\PYZus{}dataset}\PY{p}{(}\PY{n}{classes}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create Transformations}
\PY{n}{train\PYZus{}transform} \PY{o}{=} \PY{n}{create\PYZus{}training\PYZus{}transformations}\PY{p}{(}\PY{p}{)}
\PY{n}{test\PYZus{}transform} \PY{o}{=} \PY{n}{create\PYZus{}testing\PYZus{}transformations}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Transform data}
\PY{n}{trainset} \PY{o}{=} \PY{n}{TransformedDataset}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{train\PYZus{}transform}\PY{p}{)}
\PY{n}{testset} \PY{o}{=} \PY{n}{TransformedDataset}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{test\PYZus{}transform}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{trainset}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{testset}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loading preprocessed data from disk{\ldots}
torch.Size([5712, 1, 84, 84])
torch.Size([1311, 1, 84, 84])
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{n}{trainloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}
    \PY{n}{trainset}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{num\PYZus{}workers}\PY{o}{=}\PY{l+m+mi}{2}
\PY{p}{)}
\PY{n}{testloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}
    \PY{n}{testset}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{num\PYZus{}workers}\PY{o}{=}\PY{l+m+mi}{2}
\PY{p}{)}

\PY{c+c1}{\PYZsh{} show sample images}

\PY{n}{images} \PY{o}{=} \PY{p}{[}\PY{n}{x\PYZus{}train}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{)}\PY{p}{]}
\PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{axes} \PY{o}{=} \PY{n}{axes}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{p}{)}
\PY{k}{for} \PY{n}{img}\PY{p}{,} \PY{n}{ax} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{images}\PY{p}{,} \PY{n}{axes}\PY{p}{)}\PY{p}{:}
    \PY{n}{ax}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gray}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_114_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    As you can see from above, the Brain Tumor MRI Dataset contains
different types of brain MRI images. The images have been
size-normalized and objects remain centered in fixed-size images.

    \paragraph{2.1.2 Build Convolutional Neural Network
Model}\label{build-convolutional-neural-network-model}

    In this part, you need to build a convolutional neural network as
described below. The architecture of the model is outlined.

In the cnn.py file, complete the following functions:

\begin{itemize}
\tightlist
\item
  \_\_init\_\_: See Defining Variables section
\item
  forward: See Defining Model section
\end{itemize}

\textbf{{[}INPUT - CONV - CONV - MAXPOOL - DROPOUT - CONV - CONV -
MAXPOOL - DROPOUT - AVERAGEPOOL - FC1 - DROPOUT - FC2 - DROPOUT -
FC3{]}}

\begin{quote}
INPUT: {[}\(1\times84\times84\){]} will hold the raw pixel values of the
image, in this case, an image of width 84, height 84, and 1 RGB channel
(grayscale). This layer should give 8 filters and have appropriate
padding to maintain shape.
\end{quote}

\begin{quote}
CONV: Conv. layer will compute the output of neurons that are connected
to local regions in the input, each computing a dot product between
their weights and a small region they are connected to the input volume.
In our example architecture, we decide to set the kernel\_size to be
\(3\times3\). For example, the output of the Conv. layer may look like
\([8\times84\times84]\) if we set out\_channels to be 8 and use
appropriate paddings to maintain shape.
\end{quote}

\begin{quote}
CONV: Additional Conv. layer take outputs from above layers and applies
more filters. We set the kernel\_size to be \(3\times3\) and
out\_channels to be 32.
\end{quote}

\begin{quote}
MAXPOOL: MAXPOOL layer will perform a downsampling operation along the
spatial dimensions (width, height). With pool size of \(2\times2\),
resulting shape takes form \(16\times16\).
\end{quote}

\begin{quote}
DROPOUT: DROPOUT layer with the dropout rate of 0.2 to prevent
overfitting.
\end{quote}

\begin{quote}
CONV: Additonal Conv. layer takes outputs from above layers and applies
more filters. We set the kernel\_size to be \(3\times3\) and
out\_channels to be 32. Appropriate paddings are used to maintain shape.
\end{quote}

\begin{quote}
CONV: Additonal Conv. layer takes outputs from above layers and applies
more filters. We set the kernel\_size to be \(3\times3\) and
out\_channels to be 64. Appropriate paddings are used to maintain shape.
\end{quote}

\begin{quote}
MAXPOOL: MAXPOOL layer will perform a downsampling operation along the
spatial dimensions (width, height).
\end{quote}

\begin{quote}
DROPOUT: Dropout layer with the dropout rate of 0.2 to prevent
overfitting.
\end{quote}

\begin{quote}
AVERAGEPOOL: AVERAGEPOOL layer will perform a downsampling operation
along the spatial dimension (width, height). Checkout AdaptiveAvgPool2d
below.
\end{quote}

\begin{quote}
FC1: Dense layer which takes output from above layers, and has 256
neurons. Flatten() operations may be useful.
\end{quote}

\begin{quote}
DROPOUT: Dropout layer with the dropout rate of 0.2 to prevent
overfitting.
\end{quote}

\begin{quote}
FC2: Dense layer which takes output from above layers, and has 128
neurons.
\end{quote}

\begin{quote}
DROPOUT: Dropout layer with the dropout rate of 0.2 to prevent
overfitting.
\end{quote}

\begin{quote}
FC3: Dense layer with 4 neurons, and Softmax activation, is the final
layer. The dimension of the output space is the number of classes.
\end{quote}

\textbf{Activation function}: Use LeakyReLU with negative\_slope 0.01 as
the activation function for Conv. layers and Dense layers unless
otherwise indicated to build your model architecture

Note that while this is a suggested model design, you may use other
architectures and experiment with different layers for better results.

The following links are Pytorch documentation for the layers you are
going to use to build the CNN.

\begin{itemize}
\tightlist
\item
  \href{https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html}{Conv2d}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.nn.Linear.html}{Dense}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html}{MaxPool}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html}{AdaptiveAvgPool2d}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html}{Dropout}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html}{LeakyReLU}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.flatten.html}{Flatten}
\end{itemize}

Lastly, if you would like to experiment with additional layers, explore
the \href{https://pytorch.org/docs/stable/nn.html}{torch.nn api}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} Show the architecture of the model}
\PY{n}{achi} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./data/images/Architecture.png}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{achi}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<matplotlib.image.AxesImage at 0x267bf1ed3d0>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_118_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subparagraph{Defining model}\label{defining-model}

    You now need to complete the \texttt{\_\_init\_\_()} function and the
\texttt{forward()} function in cnn.py to define your model structure.

Your model is required to have at least 2 convolutional layers and at
least 2 dense layers. Ensuring that these requirements are met will earn
you 5pts.

Once you have defined a model structure you may use the cell below to
visually examine your architecture. However, there's no points for the
notebook cell output because the architecture is tested on Gradescope.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} You can compare your architecture with the \PYZsq{}Architecture.png\PYZsq{}}
\PY{n}{net} \PY{o}{=} \PY{n}{CNN}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{net}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
CNN(
  (feature\_extractor): Sequential(
    (0): Conv2d(1, 8, kernel\_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative\_slope=0.01, inplace=True)
    (2): Conv2d(8, 32, kernel\_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): LeakyReLU(negative\_slope=0.01, inplace=True)
    (4): MaxPool2d(kernel\_size=2, stride=2, padding=0, dilation=1,
ceil\_mode=False)
    (5): Dropout(p=0.2, inplace=False)
    (6): Conv2d(32, 32, kernel\_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): LeakyReLU(negative\_slope=0.01, inplace=True)
    (8): Conv2d(32, 64, kernel\_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): LeakyReLU(negative\_slope=0.01, inplace=True)
    (10): MaxPool2d(kernel\_size=2, stride=2, padding=0, dilation=1,
ceil\_mode=False)
    (11): Dropout(p=0.2, inplace=False)
  )
  (avg\_pooling): AdaptiveAvgPool2d(output\_size=(7, 7))
  (classifier): Sequential(
    (0): Flatten(start\_dim=1, end\_dim=-1)
    (1): Linear(in\_features=3136, out\_features=256, bias=True)
    (2): LeakyReLU(negative\_slope=0.01, inplace=True)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in\_features=256, out\_features=128, bias=True)
    (5): LeakyReLU(negative\_slope=0.01, inplace=True)
    (6): Dropout(p=0.1, inplace=False)
    (7): Linear(in\_features=128, out\_features=4, bias=True)
  )
)
    \end{Verbatim}

    \subparagraph{Local Test - Model
Architecture}\label{local-test---model-architecture}

The test below tests if your model architecture is compatible with the
input.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestCNN}

\PY{n}{TestCNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}model\PYZus{}architecture}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}model\PYZus{}architecture}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_model\_architecture passed!
    \end{Verbatim}

    \paragraph{2.1.3 Training and Tuning the Model {[}Required for grad,
Bonus for
undergrad{]}}\label{training-and-tuning-the-model-required-for-grad-bonus-for-undergrad}

    \textbf{Training:} You have to implement the function to be used in both
the train step and val step of each epoch. Implement
\texttt{run\_epoch()} in cnn\_trainer.py.

Hint 1: If you see any mismatch errors for torch tensors, your tensors
are on different devices. Use \texttt{.to(self.device)} on each tensor
to move the tensors to the same device.

Hint 2: The model, criterion/loss function, optimizer, and scheduler are
all set in \texttt{train()}, so you don't need to make new ones
yourself.

Hint 3: Think about what is different between the training loop and the
evaluation loop. What needs to be done during training that is not done
in evaluation?

The following links are to Pytorch documentation you may find helpful.

\begin{itemize}
\tightlist
\item
  \href{https://pytorch.org/docs/stable/optim.html}{optim}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.optim.Adamax.html}{Adamax}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html}{CrossEntropyLoss}
\item
  \href{https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html}{ExponentialLR}
\end{itemize}

    \textbf{Tuning:} Next, we train and optimize the network. You can set
the hyperparameters in \texttt{tune()} in cnn\_trainer.py. Start with
default values to verify your training loop works correctly, then
experiment with different settings to improve accuracy.

If your hyperparameters are set properly, you should see the loss of the
validation set decreased and the value of accuracy increased.

\begin{itemize}
\item
  Recommended Batch Sizes fall in the range 32-512 (use powers of 2)
\item
  Recommended Epoch Counts fall in the range 5-10
\item
  Recommended Learning Rates fall in the range .001-.01
\end{itemize}

\textbf{Expected Result:}

Your model's performance will be evaluated based on its highest
validation accuracy across all epochs. The point distribution is as
follows:

\begin{itemize}
\tightlist
\item
  Below \(70\%\) earns 2 pts (0.3\% Bonus for Undergrad)
\item
  \(70\%\) to \(74.9\%\) earns 2pts (4pts total, 0.6\% Bonus for
  Undergrad)
\item
  \(75\%\) to \(79.9\%\) earns 2pts more (6pts total, 0.9\% Bonus for
  Undergrad)
\item
  \(80\%\)+ earns 2pts more (8pts total, 1.2\% Bonus for Undergrad)
\end{itemize}

Your training must take around 5 - 10 minutes, otherwise it will timeout
on gradescope. For this reason, we highly recommend keeping number of
epochs below 10 and optimizing other hyperparameters if you're unable to
achieve optimal accuracy with 10 epochs. As a reference, it took us 5
minutes to achieve 80\%+ accuracy on CPU.

Note: If you would like to automate the tuning process, you can use a
nested for loop to search for the hyperparameter that achieves the
accuracy. You could also look into
\href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\#sklearn.model_selection.GridSearchCV}{grid
search} for hyperparameter optimization.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{cnn}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{CNN}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{cnn\PYZus{}trainer}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{Trainer}

\PY{n}{net} \PY{o}{=} \PY{n}{CNN}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Choose best device to speed up training}
\PY{k}{if} \PY{n}{torch}\PY{o}{.}\PY{n}{cuda}\PY{o}{.}\PY{n}{is\PYZus{}available}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n}{device} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cuda}\PY{l+s+s2}{\PYZdq{}}
\PY{k}{else}\PY{p}{:}
    \PY{n}{device} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cpu}\PY{l+s+s2}{\PYZdq{}}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Using }\PY{l+s+si}{\PYZob{}}\PY{n}{device}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ device}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{trainer} \PY{o}{=} \PY{n}{Trainer}\PY{p}{(}
    \PY{n}{net}\PY{p}{,}
    \PY{n}{trainset}\PY{p}{,}
    \PY{n}{testset}\PY{p}{,}
    \PY{n}{device}\PY{o}{=}\PY{n}{device}\PY{p}{,}
\PY{p}{)}
\PY{n}{trainer}\PY{o}{.}\PY{n}{tune}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Using cpu device
Epoch 1: Validation Loss: 0.84, Validation Accuracy: 0.685
Epoch 2: Validation Loss: 0.61, Validation Accuracy: 0.746
Epoch 3: Validation Loss: 0.67, Validation Accuracy: 0.735
Epoch 4: Validation Loss: 0.48, Validation Accuracy: 0.805
Epoch 5: Validation Loss: 0.66, Validation Accuracy: 0.735
Epoch 6: Validation Loss: 0.53, Validation Accuracy: 0.790
Epoch 7: Validation Loss: 0.43, Validation Accuracy: 0.843
    \end{Verbatim}

    \paragraph{2.1.4 Examine loss plots {[}Required for grad, Bonus for
undergrad{]}}\label{examine-loss-plots-required-for-grad-bonus-for-undergrad}

    To achieve full credit, your loss must be decreasing and accuracy must
be increasing gradually.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} list all data in history}
\PY{n}{train\PYZus{}loss}\PY{p}{,} \PY{n}{train\PYZus{}accuracy}\PY{p}{,} \PY{n}{val\PYZus{}loss}\PY{p}{,} \PY{n}{val\PYZus{}accuracy} \PY{o}{=} \PY{n}{trainer}\PY{o}{.}\PY{n}{get\PYZus{}training\PYZus{}history}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} summarize history for accuracy and loss}
\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{train\PYZus{}accuracy}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{val\PYZus{}accuracy}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{model accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{epoch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{val}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{upper left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{train\PYZus{}loss}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{val\PYZus{}loss}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{model loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{epoch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{val}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{upper left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_130_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_130_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestCNN}

\PY{n}{TestCNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}cnn\PYZus{}train\PYZus{}loss\PYZus{}plot}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}cnn\PYZus{}train\PYZus{}loss\PYZus{}plot}\PY{p}{(}\PY{n}{trainer}\PY{p}{)}
\PY{n}{TestCNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}cnn\PYZus{}test\PYZus{}loss\PYZus{}plot}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}cnn\PYZus{}test\PYZus{}loss\PYZus{}plot}\PY{p}{(}\PY{n}{trainer}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \paragraph{2.1.5 Examine Confusion Matrix {[}Required for grad, Bonus
for
undergrad{]}}\label{examine-confusion-matrix-required-for-grad-bonus-for-undergrad}

    To get full credit, all the diagonal entries in your confusion matrix
should be above 0.5. This ensures our model has reasonable accuracy
across all classes. You can use the test below to verify the same.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{TestCNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}cnn\PYZus{}confusion\PYZus{}matrix}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}cnn\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{trainer}\PY{p}{,} \PY{n}{testloader}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_134_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
test\_cnn\_confusion\_matrix passed!
    \end{Verbatim}

    Test accuracy is not tested on this homework but we include it here for
completeness.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}classes}\PY{p}{,} \PY{n}{y\PYZus{}gt\PYZus{}classes} \PY{o}{=} \PY{n}{trainer}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{testloader}\PY{p}{)}
\PY{n}{y\PYZus{}pred\PYZus{}prob} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{.}\PY{n}{values}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{ConfusionMatrixDisplay}\PY{p}{,} \PY{n}{accuracy\PYZus{}score}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test accuracy: }\PY{l+s+si}{\PYZob{}}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}gt\PYZus{}classes}\PY{p}{,}\PY{+w}{ }\PY{n}{y\PYZus{}pred\PYZus{}classes}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Test accuracy: 0.8428680396643783
    \end{Verbatim}

    \subsubsection{\texorpdfstring{2.2 Exploring Deep CNN Architectures
{[}2.5\% Bonus for All{]}
{\textbf{{[}W{]}}}}{2.2 Exploring Deep CNN Architectures {[}2.5\% Bonus for All{]} {[}W{]}}}\label{exploring-deep-cnn-architectures-2.5-bonus-for-all-w}

    \paragraph{2.2.1 Abating Vanishing Gradients {[}1.5\% Bonus for
All{]}}\label{abating-vanishing-gradients-1.5-bonus-for-all}

    The network you have produced is rather simple relative to many of those
used in industry and research. Researchers have worked to make CNN
models deeper and deeper over the past years in an effort to gain higher
accuracy in predictions. While your model is only a handful of layers
deep, some state of the art deep architectures may include up to 150
layers. However, this process has not been without challenges.

A common issue with deep CNN architectures is the vanishing gradient
problem. Small weights deep into the network can contribute smaller and
smaller gradients as backpropagation travels back in the network, and
the initial layers may end up seeing very small gradient updates that
can encounter floating point accuracy errors depending on the hardware,
resulting in frozen weights that are never updated. Vanishing gradients
accumulate along the networks layers, which becomes a big problem in
deeper architectures.

One of the first successful deep CNNs is known as ResNet (Residual
Networks) which uses what are known as skip connections to allow the
flow of data through the network to skip layers. Take a moment to
explore how ResNet tackles the vanishing gradient problem by reading the
original research paper here: https://arxiv.org/abs/1512.03385.

    \textbf{Question:} In 1-2 sentences, explain how residual `skip
connections' address the vanishing gradient problem.

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Residual skip connections address the vanishing gradient problem by
creating a direct path that allows gradients to flow uninterrupted
during backpropagation. This ensures that the gradient signal can
effectively reach and update the weights in the earlier layers of deep
networks, rather than diminishing to zero as it passes through many
transformation layers.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \paragraph{2.2.2 Abating Internal Covariate Shift {[}1.0\% Bonus for
All{]}}\label{abating-internal-covariate-shift-1.0-bonus-for-all}

    Another common strategy to mitigate gradient issues and build deeper
networks is to use a learnable Batch Normalization layer after each
activation layer, and before the nonlinearity
(i.e.~\(\sigma(BN(Wx+b))\)).
\[y=\frac{x-\mu_\mathcal{B}}{\sigma_\mathcal{B}}\gamma+\beta\] Where the
mean \(\mu_\mathcal{B}=\frac{1}{|\mathcal{B}|}\sum_{x\in\mathcal{B}}x\)
and variance
\(\sigma_\mathcal{B}^2=\frac{1}{|\mathcal{B}|}\sum_{x\in\mathcal{B}}(x-\mu_\mathcal{B})^2\)
are taken over the current training mini-batch \(\mathcal{B}\). The
learnable parameters \(\gamma\) and \(\beta\) are updated in
backpropagation. Read through the
\href{https://arxiv.org/pdf/1502.03167}{original Batch Normalization
paper}, particularly sections 2 and 3 for a better grasp of the
formulation and motivation behind activation normalization.

    \textbf{Question:} In 3-5 sentences, explain the problem of internal
covariate shift and how Batch Normalization helps to reduce this issue.

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Internal covariate shift is when the distribution of activations in each
layer keeps changing during training as earlier layers' weights are
updated. This means deeper layers are constantly having to re-adapt to a
new distribution, which slows and destabilizes learning. Batch
Normalization addresses this by normalizing the inputs to have a zero
mean and unit variance, then re-scaling and shifting them with learned
parameters. This stabilizes the input distribution across the network,
allowing for faster convergence and the use of higher learning rates.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \subsection{\texorpdfstring{Q3: SVM {[}20 pts{]} {\textbf{{[}P{]}}}
\textbar{}
{\textbf{{[}W{]}}}}{Q3: SVM {[}20 pts{]} {[}P{]} \textbar{} {[}W{]}}}\label{q3-svm-20-pts-p-w}

    Support Vector Machines (SVMs) aim to find a hyperplane that separates
data points of different classes with the maximum margin. The larger the
margin, the better the model can generalize to unseen data. If the data
has no perfectly separating hyperplane, it uses a regularization
constant \(C\) to weigh sometimes competing objectives: maximizing train
accuracy and maximizing the margin size. SVMs are a pretty powerful tool
with some adaptation, but out-of-the-box, they do need some help.

    \subsubsection{\texorpdfstring{3.1 Picking Performant Constructions
{[}5pts{]}
{\textbf{{[}W{]}}}}{3.1 Picking Performant Constructions {[}5pts{]} {[}W{]}}}\label{picking-performant-constructions-5pts-w}

    For this exercise, we will use \texttt{SVC} from scikit-learn with a
linear kernel. We also have some data that we'd like to classify. Here's
a plot of that data:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{x\PYZus{}1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.46}\PY{p}{,} \PY{l+m+mf}{1.96}\PY{p}{,} \PY{l+m+mf}{2.94}\PY{p}{,} \PY{l+m+mf}{3.71}\PY{p}{,} \PY{l+m+mf}{0.81}\PY{p}{,} \PY{l+m+mf}{1.93}\PY{p}{,} \PY{l+m+mf}{2.95}\PY{p}{,} \PY{l+m+mf}{4.51}\PY{p}{]}\PY{p}{)}  \PY{c+c1}{\PYZsh{} (N,)}
\PY{n}{x\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.76}\PY{p}{,} \PY{l+m+mf}{1.56}\PY{p}{,} \PY{l+m+mf}{1.99}\PY{p}{,} \PY{l+m+mf}{2.32}\PY{p}{,} \PY{l+m+mf}{0.10}\PY{p}{,} \PY{l+m+mf}{2.62}\PY{p}{,} \PY{l+m+mf}{2.80}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mf}{1.13}\PY{p}{]}\PY{p}{)}  \PY{c+c1}{\PYZsh{} (N,)}
\PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}  \PY{c+c1}{\PYZsh{} (N,)}
\PY{n}{X} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{column\PYZus{}stack}\PY{p}{(}\PY{p}{(}\PY{n}{x\PYZus{}1}\PY{p}{,} \PY{n}{x\PYZus{}2}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} (N, 2)}

\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{n}{y}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_150_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    As it stands, there is no hyperplane that would separate these points.
But surely there's some information here! N=8 is not really enough to
get great inductive guarantees about any trends about what this data
might be, but let's plug away anyways. We'll use a transformation
\(f:\mathbb{R}^2 \rightarrow \mathbb{R}\) that maps the 2 features into
a single combined feature. Even with the dimensionality reduction, if we
pick a good function, the data may still be separable.

We have provided several candidate functions that transform the dataset.
It's your job to determine which of the candidate functions would result
in linear separability (it may be more than 1).

There's a few ways you could investigate this. You could just do the
math, you could apply the transforms and run
\texttt{SVC(kernel=\textquotesingle{}linear\textquotesingle{})}, you
could plot the result, etc. For this question, you do not need to show
your work. Any evidence you show might help us grant you extra credit,
but you just need to indicate whether each kernel results in linear
separability.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} These are the candidate transforms that you\PYZsq{}ll need to evaluate}


\PY{k}{def}\PY{+w}{ }\PY{n+nf}{f1}\PY{p}{(}\PY{n}{feature\PYZus{}1}\PY{p}{,} \PY{n}{feature\PYZus{}2}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{feature\PYZus{}1}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2} \PY{o}{+} \PY{n}{feature\PYZus{}2}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}


\PY{k}{def}\PY{+w}{ }\PY{n+nf}{f2}\PY{p}{(}\PY{n}{feature\PYZus{}1}\PY{p}{,} \PY{n}{feature\PYZus{}2}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{feature\PYZus{}1}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}


\PY{k}{def}\PY{+w}{ }\PY{n+nf}{f3}\PY{p}{(}\PY{n}{feature\PYZus{}1}\PY{p}{,} \PY{n}{feature\PYZus{}2}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{feature\PYZus{}1}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2} \PY{o}{+} \PY{n}{feature\PYZus{}2}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}


\PY{k}{def}\PY{+w}{ }\PY{n+nf}{f4}\PY{p}{(}\PY{n}{feature\PYZus{}1}\PY{p}{,} \PY{n}{feature\PYZus{}2}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{feature\PYZus{}2}\PY{p}{)}


\PY{k}{def}\PY{+w}{ }\PY{n+nf}{f5}\PY{p}{(}\PY{n}{feature\PYZus{}1}\PY{p}{,} \PY{n}{feature\PYZus{}2}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{feature\PYZus{}2} \PY{o}{\PYZhy{}} \PY{n}{feature\PYZus{}1}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{} OPTIONAL: Investigate the given functions with some code\PYZhy{}based approaches           \PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}


\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{SVC}

\PY{n}{linear\PYZus{}model} \PY{o}{=} \PY{n}{SVC}\PY{p}{(}\PY{n}{kernel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{linear}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{candidateFunctions} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{f1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{f2}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{f3}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f4}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{f4}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{f5}\PY{p}{\PYZcb{}}

\PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{func} \PY{o+ow}{in} \PY{n}{candidateFunctions}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n}{xNew} \PY{o}{=} \PY{n}{func}\PY{p}{(}\PY{n}{x\PYZus{}1}\PY{p}{,} \PY{n}{x\PYZus{}2}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{linear\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{xNew}\PY{p}{,} \PY{n}{y}\PY{p}{)}
    \PY{n}{acc} \PY{o}{=} \PY{n}{linear\PYZus{}model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{xNew}\PY{p}{,} \PY{n}{y}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{name}\PY{l+s+si}{:}\PY{l+s+s2}{\PYZlt{}10}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ | }\PY{l+s+si}{\PYZob{}}\PY{n}{acc}\PY{l+s+si}{:}\PY{l+s+s2}{\PYZlt{}10.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ | }\PY{l+s+si}{\PYZob{}}\PY{n}{acc}\PY{+w}{ }\PY{o}{==}\PY{+w}{ }\PY{l+m+mf}{1.0}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}


\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}                                  END OF YOUR CODE                                   \PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
f1         | 0.50       | False
f2         | 0.50       | False
f3         | 0.50       | False
f4         | 0.75       | False
f5         | 0.62       | False
    \end{Verbatim}

    OPTIONAL: Investigate the given functions with some written approaches

    Indicate all of the given functions that cause the provided data to be
linearly separable by a hyperplane. (more than 1 function may apply)
{[}5pts{]}

\textbf{Your Answer Here:}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

none of these functions achieve perfect linear separability

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \subsubsection{\texorpdfstring{3.2 Custom Feature Engineering {[}5pts{]}
{\textbf{{[}P{]}}}}{3.2 Custom Feature Engineering {[}5pts{]} {[}P{]}}}\label{custom-feature-engineering-5pts-p}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{data/artificial\PYZus{}data.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{X} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x\PYZus{}1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x\PYZus{}2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{to\PYZus{}numpy}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} (N, 2)}
\PY{n}{y} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{to\PYZus{}numpy}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} (N,)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot the data}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{n}{y}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_159_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    We have the above 2D dataset. Natively, SVM won't be able to handle this
with 100\% accuracy because the data is not linearly separable. There's
no line in the Cartesian plane that would separate these labels.

    In \texttt{svm.py} complete \texttt{feature\_construction}. You must
take the data here and transform it, so that this data is perfectly
linearly separable, and a SVM would be able to fit to the data with
100\% training accuracy.

We won't provide a local test for this. If you'd like to try the SVM fit
(and find out what's not fitting), you'll need to set up the code
yourself. Remember to set the kernel type to `linear' in the SVC,
\texttt{SVC(kernel=\textquotesingle{}linear\textquotesingle{})}. The
default kwarg for \texttt{kernel} makes the algorithm way more
performant, which we'll explore later.

    \subsubsection{\texorpdfstring{3.3 Kernel Trick {[}10 pts{]}
{\textbf{{[}P{]}}}}{3.3 Kernel Trick {[}10 pts{]} {[}P{]}}}\label{kernel-trick-10-pts-p}

    In the previous sections, we used feature engineering to make our data
linearly separable. In this section, you will explore another, more
powerful method to make data linearly separable - ``the kernel trick''.

The kernel trick makes data linearly separable by projecting it to a
higher dimensionality space. This allows for data that might not be
linearly separable in one dimensionality to become linearly separable in
another. Though, as you'll see, there's never any actual projection
happening.

    \paragraph{Justification for the
trick}\label{justification-for-the-trick}

If you're not interested in the derivation, you can collapse and skip
this section by clicking on the arrow to the left of this cell.

    We have a dataset
\((x^{\{1\}}, y^{\{1\}}), (x^{\{2\}}, y^{\{2\}}), \dots, (x^{\{N\}}, y^{\{N\}})\)
where each data-label pair is
\((x^{\{i\}}, y^{\{i\}}) \in \mathbb{R}^D \times \{-1, 1\}\).

What we want is a hyperplane of the form \(w\cdot x + b = 0\) that
separates all data with labels -1 and 1 as purely as possible. So, our
decision function is just \(f(x)=\textsf{sign}(w\cdot x + b)\). How can
we derive those weights?

A correct classifier would satisfy
\(y^{\{i\}}(w\cdot x^{\{i\}} + b) > 0\). If the label is negative and
the prediction is negative, the product should be positive. If the label
is positive and the prediction is positive, the product should be
positive. There are two problems with this. 1. We can scale \(w\) and
\(b\) and get equivalent results. 2. We have no margin for error! A
perfectly valid classifier might get arbitrarily close to the train
points. However, we must assume that the underlying distribution doesn't
belong in a convex hull of the train points. We need to keep our target
hyperplane as far away from the train points as we can.

    We can just strengthen our constraints. We demand
\(y^{\{i\}}(w\cdot x^{\{i\}} + b) \geq 1\) (widen the required margin)
but also seek to maximize that margin.

Because of our choice of widened margin 1, the margin planes are
\(w\cdot x^{\{i\}} + b = 1\) and \(w\cdot x^{\{i\}} + b = -1\). The
distance between the two planes can be derived from point to plane
distance. Choose \(x_+\) on the positive plane. The distance from that
point to the negative plane is
\(\frac{(w\cdot x_+ + b) - (-1)}{\|w\|}\). Being on the positive plane
means \(w\cdot x_+ + b = 1\), so the distance between those planes is
\(\frac{(1) - (-1)}{\|w\|}=\frac{2}{\| w \|}\). We need to maximize this
margin, but the derivative isn't great, so we need an alternative form.
Being careful with constants, signs, and monotonic composition, we get
the following form:
\[ \max \frac{2}{\| w \|} = \max \frac{1}{\| w \|} = \min \| w \| = \min \| w \|^2 = \min \frac{\|w\|^2}{2} \]
and the derivative is much more helpful, leaving us with the following
problem:

\[\begin{cases}
    \min \frac{\|w\|^2}{2} & \\
    \text{s.t. } y^{\{i\}}(w\cdot x^{\{i\}} + b) \geq 1
\end{cases}\]

One issue with this is that most data unfortunately won't have any
solutions here. We need to permit margin violations and even
misclassifications with a slack variable. We should of course minimize
this slack, since having misclassifications in training is not ideal.
This complicates the problem:

\[\begin{cases}
    \min \frac{\|w\|^2}{2} + C\cdot \sum_{i=1}^N \xi_i & \\
    \text{s.t. }\;\; y^{\{i\}}(w\cdot x^{\{i\}} + b) \geq 1 - \xi_i & \\
    \;\;\;\;\;\;\;\; \xi_i \geq 0 &
\end{cases}\]

\emph{Note: \(C\) is a hyperparameter that dictates how much you care
about misclassifications vs.~how much you care about margin.}

    To solve, we construct the Lagrangian:

\[\mathcal{L} = \frac{\|w\|^2}{2} + C\cdot \sum_i \xi_i - \sum_i \lambda_i[y^{\{i\}}(w\cdot x^{\{i\}} + b) - 1 + \xi_i] - \sum_i \lambda_i'[\xi_i]\]

Then differentiate:

\[\frac{d\mathcal{L}}{dw} = w - \sum_i \lambda_i y^{\{i\}} x^{\{i\}} := 0 \;\;\implies\;\; w = \sum_i \lambda_i y^{\{i\}} x^{\{i\}}\]
\[\frac{d\mathcal{L}}{db} = - \sum_i \lambda_i y^{\{i\}} := 0 \;\;\implies\;\; \sum_i \lambda_i y^{\{i\}} = 0\]
\[\frac{d\mathcal{L}}{d\xi_i} = C - \lambda_i - \lambda_i' := 0 \;\;\implies\;\; \lambda_i = C - \lambda_i' \;\;\implies\;\; \lambda_i \leq C \]

If we can solve for the Lagrange multipliers in the Lagrangian dual,
then we have our \(w\) and \(b\).

\emph{If you want to exercise your KKT chops, you'll notice we don't
actually have \(b\) here, only \(w\). The solution for \(b\)
precipitates from the complementary slackness constraints. You can also
derive it after you have \(w\), if you notice what \(\lambda_i\) means.
If \(\lambda_i \neq 0\), then \(x^{\{i\}}\) must be a support vector,
and we impose a strict margin of \(\geq 1/\|w\|\) from any support
vector to the hyperplane. That's a linear programming problem.}

Now, back to the dervation. Impose the identities derived from the
stationarity conditions back onto the Lagrangian.

    \[\mathcal{L} = \frac{1}{2}\|w\|^2 + C\sum_i\xi_i - \sum_i \lambda_i y^{\{i\}}(w\cdot x^{\{i\}}) - \sum_i \lambda_i y^{\{i\}} b + \sum_i \lambda_i - \sum_i \lambda_i\xi_i - \sum_i \lambda_i'\xi_i\]
\[\mathcal{L} = \frac{1}{2}\left\|\left[\sum_i \lambda_i y^{\{i\}} x^{\{i\}}\right]\right\|^2 - \sum_i \lambda_i y^{\{i\}}\left(\left[\sum_j \lambda_j y^{\{j\}} x^{\{j\}}\right]\cdot x^{\{i\}}\right) -b\cdot [0] + \sum_i \lambda_i - \sum_i \lambda_i\xi_i - \sum_i \lambda_i'\xi_i + C\sum_i\xi_i\]
\[\mathcal{L} = \frac{1}{2}\cdot\left(\left[\sum_i \lambda_i y^{\{i\}} x^{\{i\}}\right]\cdot\left[\sum_j \lambda_j y^{\{j\}} x^{\{j\}}\right]\right) - \sum_i \lambda_i y^{\{i\}}\left(\left[\sum_j \lambda_j y^{\{j\}} x^{\{j\}}\right]\cdot x^{\{i\}}\right) + \sum_i \lambda_i - \sum_i \lambda_i\xi_i - \sum_i \lambda_i'\xi_i + \sum_i C\xi_i\]
\[\mathcal{L} = \frac{1}{2}\cdot\left(\sum_i\sum_j \lambda_i\lambda_j y^{\{i\}}y^{\{j\}} (x^{\{i\}} \cdot x^{\{j\}})\right) - \left(\sum_i\sum_j \lambda_i\lambda_j y^{\{i\}}y^{\{j\}} (x^{\{i\}} \cdot x^{\{j\}})\right) + \sum_i \lambda_i + \sum_i \xi_i(C - \lambda_i - \lambda_i')\]
\[\mathcal{L} = -\frac{1}{2}\cdot\left(\sum_i\sum_j \lambda_i\lambda_j y^{\{i\}}y^{\{j\}} (x^{\{i\}} \cdot x^{\{j\}})\right) + \sum_i \lambda_i + \sum_i \xi_i[0]\]
\[\mathcal{L} = -\frac{1}{2}\cdot\left(\sum_i\sum_j \lambda_i\lambda_j y^{\{i\}}y^{\{j\}} (x^{\{i\}} \cdot x^{\{j\}})\right) + \sum_i \lambda_i\]

    We can now set up the dual, and solving for the Lagrange multipliers
will give a form for \(w\), which is precisely what fitting an SVM is.

\[\begin{cases}
    \max_\lambda \;-\frac{1}{2}\!\left(\sum_i\sum_j \lambda_i\lambda_j y^{\{i\}}y^{\{j\}} (x^{\{i\}} \cdot x^{\{j\}})\right) + \sum_i \lambda_i & \\
    \text{s.t. }\;\; \sum_i \lambda_i y^{\{i\}} \;\;\left(\text{from the derivative } \frac{d\mathcal{L}}{db}\right) & \\
    \;\;\;\;\;\;\;\; 0 \leq \lambda_i \leq C \;\;\left(\text{from the derivative } \frac{d\mathcal{L}}{d\xi_i}\right) &
\end{cases}\]

    \paragraph{The Kernel Trick}\label{the-kernel-trick}

    In case you skipped the derivation, this is fitting an SVM looks like:

\[\begin{cases}
    \max_\lambda \;-\frac{1}{2}\!\left(\sum_i\sum_j \lambda_i\lambda_j y^{\{i\}}y^{\{j\}} (x^{\{i\}} \cdot x^{\{j\}})\right) + \sum_i \lambda_i & \\
    \text{s.t. }\;\; \sum_i \lambda_i y^{\{i\}} & \\
    \;\;\;\;\;\;\;\; 0 \leq \lambda_i \leq C &
\end{cases}\]

We need to find the support parameters \(\lambda_i\) that maximize this
expression. These \(\lambda_i\) will let us solve for \(w\) and \(b\).

    The so-called ``kernel trick'' is actually a technically wrong extension
of the derived formula for a maximum-margin hyperplane. Take a look at
the learning objective. Zoom in on one term:
\[(x^{\{i\}} \cdot x^{\{j\}})\] This functionally measures the
similarity of datum \(i\) to datum \(j\) directly. The trouble with SVM,
as we saw in the previous sections, was that the data may just not be
linearly separable in the features that we have collected. In the
feature engineering, you may have made polynomial or exponential or any
number of transformations to try to get the data to be separable. Let's
do that here! Make up some mapping
\(\phi:\mathbb{R}^D \rightarrow \mathbb{R}^{D'}\) that maps the data in
the \(D\) feature space to some new space of dimensionality \(D'\)
(ideally with \(D'\gg D\)). Then, we'll just map \(x^{\{i\}}\) and
\(x^{\{j\}}\) into that new space before taking their dot product. If we
pick a sensible/continuous/smooth-ish mapping, then data that's similar
in the low dimensional space will stay similar in the high dimensional
space, but the curse of dimensionality becomes the blessing of
dimensionality! We get these tight knit groups of data that are strongly
similar in many of the feature pairs. \[\begin{cases}
    \max_\lambda \;-\frac{1}{2}\!\left(\sum_i\sum_j \lambda_i\lambda_j y^{\{i\}}y^{\{j\}} \big(\phi(x^{\{i\}}) \cdot \phi(x^{\{j\}})\big) \right) + \sum_i \lambda_i & \\
    \text{s.t. }\;\; \sum_i \lambda_i y^{\{i\}} & \\
    \;\;\;\;\;\;\;\; 0 \leq \lambda_i \leq C &
\end{cases}\] If you have a good function \(\phi\) in mind for your
problem, that's great! But generally, there's not an excellent closed
form solution, so we may just want to make the projected space \(D'\)
massive so we hit at least a few useful features. If we blow up \(D'\),
then representing \(\phi\) and calculating
\(\big(\phi(x^{\{i\}}) \cdot \phi(x^{\{j\}})\big)\) might become quite
expensive. This is the eponymous kernel trick! Replace
\(\big(\phi(x^{\{i\}}) \cdot \phi(x^{\{j\}})\big)\) with a kernel matrix
\(K[i,j]\) with shape (N, N). \(K[i,j]\) describes the similarity of
datum \(i\) to datum \(j\). So, the kernel can be any matrix that looks
like pairwise inner products. We only need: - kernel needs to be
symmetric. (since \(a\cdot b = b\cdot a\)) - kernel needs to be
positive-semidefinite.
(\href{https://en.wikipedia.org/wiki/Mercer\%27s_theorem}{Mercer's
Theorem}) \[\begin{cases}
    \max_\lambda \;-\frac{1}{2}\!\left(\sum_i\sum_j \lambda_i\lambda_j y^{\{i\}}y^{\{j\}} K[i,\,j] \right) + \sum_i \lambda_i & \\
    \text{s.t. }\;\; \sum_i \lambda_i y^{\{i\}} & \\
    \;\;\;\;\;\;\;\; 0 \leq \lambda_i \leq C &
\end{cases}\] So, when the \(\phi\) you want makes calculating
\(\big(\phi(x^{\{i\}}) \cdot \phi(x^{\{j\}})\big)\) intractible, just
find some closed-form for the solution that you can compute quickly and
stuff it into a kernel.

    \paragraph{\texorpdfstring{3.3.1 Build a Kernel {[}5pts{]}
{\textbf{{[}P{]}}}}{3.3.1 Build a Kernel {[}5pts{]} {[}P{]}}}\label{build-a-kernel-5pts-p}

    In \texttt{svm.py} complete \texttt{kernel\_construction}. Given a set
of data and a callable function \(\phi\), build up the kernel matrix
element-by-element. You're fine to use loops here, since the point of
this exercise is that this is an inefficient way to build kernels in
general. No need to make your code timely (so we won't give you massive
inputs that stall out the Gradescope time).

The kernel that you make can genuinely be passed into scikit-learn's
SVC. It will query your matrix and build the corresponding SVM.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{36}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestSVM}

\PY{n}{TestSVM}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}kernel}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}kernel}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_kernel passed!
    \end{Verbatim}

    Now, the kernel that you make is going to be questionably useful. It's
tricky to define a good map for a general problem. Let's see if a phi
generating degree 2 polynomials works for the following problem:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{37}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{svm}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{accuracy\PYZus{}score}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{SVC}

\PY{c+c1}{\PYZsh{} Example data}
\PY{n}{x\PYZus{}1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.46}\PY{p}{,} \PY{l+m+mf}{1.96}\PY{p}{,} \PY{l+m+mf}{2.94}\PY{p}{,} \PY{l+m+mf}{3.71}\PY{p}{,} \PY{l+m+mf}{1.81}\PY{p}{,} \PY{l+m+mf}{1.93}\PY{p}{,} \PY{l+m+mf}{2.95}\PY{p}{,} \PY{l+m+mf}{4.51}\PY{p}{]}\PY{p}{)}
\PY{n}{x\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.76}\PY{p}{,} \PY{l+m+mf}{1.56}\PY{p}{,} \PY{l+m+mf}{1.99}\PY{p}{,} \PY{l+m+mf}{2.32}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mf}{0.50}\PY{p}{,} \PY{l+m+mf}{2.62}\PY{p}{,} \PY{l+m+mf}{2.80}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mf}{1.13}\PY{p}{]}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\PY{n}{X} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{column\PYZus{}stack}\PY{p}{(}\PY{p}{(}\PY{n}{x\PYZus{}1}\PY{p}{,} \PY{n}{x\PYZus{}2}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{n}{y}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Feature construction}
\PY{k}{def}\PY{+w}{ }\PY{n+nf}{phi}\PY{p}{(}\PY{n}{datum}\PY{p}{)}\PY{p}{:}
    \PY{n}{projected} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{p}{)}\PY{p}{)}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*}\PY{o}{*} \PY{l+m+mi}{2}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{*}\PY{o}{*} \PY{l+m+mi}{2}
    \PY{k}{return} \PY{n}{projected}


\PY{c+c1}{\PYZsh{} Fit with kernel}
\PY{n}{custom\PYZus{}kernel} \PY{o}{=} \PY{n}{svm}\PY{o}{.}\PY{n}{kernel\PYZus{}construction}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{phi}\PY{p}{)}
\PY{n}{svm\PYZus{}model} \PY{o}{=} \PY{n}{SVC}\PY{p}{(}\PY{n}{kernel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{precomputed}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{svm\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{custom\PYZus{}kernel}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{svm\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{custom\PYZus{}kernel}\PY{p}{)}
\PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training accuracy:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{acc}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_177_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Training accuracy: 1.0
    \end{Verbatim}

    You should have reached a training accuracy of 100\%, but this kernel
really does not generalize well. With a new, less fortunately placed
data point, the data is no longer separable.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{38}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{svm}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{accuracy\PYZus{}score}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{SVC}

\PY{c+c1}{\PYZsh{} Example data}
\PY{n}{x\PYZus{}1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.46}\PY{p}{,} \PY{l+m+mf}{1.96}\PY{p}{,} \PY{l+m+mf}{2.94}\PY{p}{,} \PY{l+m+mf}{3.71}\PY{p}{,} \PY{l+m+mf}{1.81}\PY{p}{,} \PY{l+m+mf}{0.81}\PY{p}{,} \PY{l+m+mf}{1.93}\PY{p}{,} \PY{l+m+mf}{2.95}\PY{p}{,} \PY{l+m+mf}{4.51}\PY{p}{]}\PY{p}{)}
\PY{n}{x\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.76}\PY{p}{,} \PY{l+m+mf}{1.56}\PY{p}{,} \PY{l+m+mf}{1.99}\PY{p}{,} \PY{l+m+mf}{2.32}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mf}{0.50}\PY{p}{,} \PY{l+m+mf}{0.10}\PY{p}{,} \PY{l+m+mf}{2.62}\PY{p}{,} \PY{l+m+mf}{2.80}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mf}{1.13}\PY{p}{]}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\PY{n}{X} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{column\PYZus{}stack}\PY{p}{(}\PY{p}{(}\PY{n}{x\PYZus{}1}\PY{p}{,} \PY{n}{x\PYZus{}2}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{n}{y}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Feature construction}
\PY{k}{def}\PY{+w}{ }\PY{n+nf}{phi}\PY{p}{(}\PY{n}{datum}\PY{p}{)}\PY{p}{:}
    \PY{n}{projected} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{p}{)}\PY{p}{)}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*}\PY{o}{*} \PY{l+m+mi}{2}
    \PY{n}{projected}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]} \PY{o}{=} \PY{n}{datum}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{*}\PY{o}{*} \PY{l+m+mi}{2}
    \PY{k}{return} \PY{n}{projected}


\PY{c+c1}{\PYZsh{} Fit with kernel}
\PY{n}{custom\PYZus{}kernel} \PY{o}{=} \PY{n}{svm}\PY{o}{.}\PY{n}{kernel\PYZus{}construction}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{phi}\PY{p}{)}
\PY{n}{svm\PYZus{}model} \PY{o}{=} \PY{n}{SVC}\PY{p}{(}\PY{n}{kernel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{precomputed}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{svm\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{custom\PYZus{}kernel}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{svm\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{custom\PYZus{}kernel}\PY{p}{)}
\PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training accuracy:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{acc}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_179_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Training accuracy: 0.8888888888888888
    \end{Verbatim}

    \paragraph{\texorpdfstring{3.3.2 Build a Known Kernel (RBF) {[}5pts{]}
{\textbf{{[}P{]}}}}{3.3.2 Build a Known Kernel (RBF) {[}5pts{]} {[}P{]}}}\label{build-a-known-kernel-rbf-5pts-p}

    Our degree 2 polynomial kernel clearly is not the greatest tool
available. It fails to fully fit on this data, and if this were a
larger, more real dataset, it would probably lack significant
generalizability. There are better kernels that you can use. We'll
explore a kernel that actually projects into infinite dimensions: the
radial basis function kernel (RBF).

    \subparagraph{What does it mean to project into infinite
dimensions?}\label{what-does-it-mean-to-project-into-infinite-dimensions}

If you're not interested in the derivation, you can collapse and skip
this section by clicking on the arrow to the left of this cell.

    The form for the RBF kernel itself is really simple. You define the
similarity between two points \(x\) and \(y\) as the distance between
them \(\|x-y\|^2\) composed with some decreasing function. A natural
choice is \(1/x\) or \(-x\), but RBF uses the similarly reasonable
\(\exp(-\gamma x)\), where \(\gamma\) is a free hyperparameter. Thus, we
have:
\[K[i, j] = \exp\left( -\gamma\left\|x^{\{i\}}-x^{\{j\}}\right\|^2 \right)\]
This definition is how you really should intuitively approach RBF. It's
a similarity metric based on distance. But we did define
\(K[i, j]=\big(\phi(x^{\{i\}}) \cdot \phi(x^{\{j\}})\big)\), so this
begs the question, what would the implicit mapping \(\phi\) be for RBF?

    \begin{align*}
    K[i, j] &= \exp\left( -\gamma\left\|x^{\{i\}}-x^{\{j\}}\right\|^2 \right) \\
    K[i, j] &= \exp\left( -\gamma\left( \left\|x^{\{i\}}\right\|^2 + \left\|x^{\{j\}}\right\|^2 - 2x^{\{i\}}\cdot x^{\{j\}} \right) \right) \\
    K[i, j] &= \exp\left( -\gamma\left\|x^{\{i\}}\right\|^2 \right)\exp\left( -\gamma\left\|x^{\{j\}}\right\|^2 \right) \exp\left( 2\gamma (x^{\{i\}}\cdot x^{\{j\}}) \right) \\
    &\text{Use the Taylor series for }\exp \\
    K[i, j] &= \exp\left( -\gamma\left\|x^{\{i\}}\right\|^2 \right)\exp\left( -\gamma\left\|x^{\{j\}}\right\|^2 \right) \sum_{m=0}^\infty \frac{(2\gamma)^m}{m!} (x^{\{i\}}\cdot x^{\{j\}})^m \\
    &\text{Note that }(x^{\{i\}}\cdot x^{\{j\}})^m\text{ is a D-termed multinomial, so we can use the multinomial theorem} \\
    &\text{Let }\boldsymbol{\alpha}\text{ be our D-long multi-index (positive integer sequence summing to m)} \\
    K[i, j] &= \exp\left( -\gamma\left\|x^{\{i\}}\right\|^2 \right)\exp\left( -\gamma\left\|x^{\{j\}}\right\|^2 \right) \sum_{m=0}^\infty \left[ \frac{(2\gamma)^m}{m!} \cdot \sum_{\forall\boldsymbol{\alpha}, \;\Sigma\boldsymbol{\alpha}=m}\left[ \binom{m}{\boldsymbol{\alpha}}\prod_{d=1}^D (x^{\{i\}}_dx^{\{j\}}_d)^{\alpha_d} \right]\right] \\
    K[i, j] &= \exp\left( -\gamma\left\|x^{\{i\}}\right\|^2 \right)\exp\left( -\gamma\left\|x^{\{j\}}\right\|^2 \right) \sum_{m=0}^\infty \sum_{\forall\boldsymbol{\alpha}, \;\Sigma\boldsymbol{\alpha}=m}\left[ \frac{(2\gamma)^m}{m!} \cdot \frac{m!}{\prod_{d=1}^D \alpha_d!}\prod_{d=1}^D (x^{\{i\}}_dx^{\{j\}}_d)^{\alpha_d} \right] \\
    K[i, j] &= \exp\left( -\gamma\left\|x^{\{i\}}\right\|^2 \right)\exp\left( -\gamma\left\|x^{\{j\}}\right\|^2 \right) \sum_{m=0}^\infty \sum_{\forall\boldsymbol{\alpha}, \;\Sigma\boldsymbol{\alpha}=m}\left[ \frac{(2\gamma)^m}{\prod_{d=1}^D \alpha_d!} \prod_{d=1}^D \left(x^{\{i\}}_d\right)^{\alpha_d} \prod_{d=1}^D \left(x^{\{j\}}_d\right)^{\alpha_d} \right] \\
    &\text{Gather terms to make matching }i\text{ and }j\text{ parts} \\
    K[i, j] &= \sum_{m=0}^\infty \sum_{\forall\boldsymbol{\alpha}, \;\Sigma\boldsymbol{\alpha}=m}\left[ \exp\left( -\gamma\left\|x^{\{i\}}\right\|^2 \right) \cdot \exp\left( -\gamma\left\|x^{\{j\}}\right\|^2 \right) \cdot \frac{(2\gamma)^m}{\prod_{d=1}^D \alpha_d!} \cdot \prod_{d=1}^D \left(x^{\{i\}}_d\right)^{\alpha_d} \cdot \prod_{d=1}^D \left(x^{\{j\}}_d\right)^{\alpha_d} \right] \\
    K[i, j] &= \sum_{m=0}^\infty \sum_{\forall\boldsymbol{\alpha}, \;\Sigma\boldsymbol{\alpha}=m}\left[ \exp\left( -\gamma\left\|x^{\{i\}}\right\|^2 \right) \cdot \sqrt{\frac{(2\gamma)^m}{\prod_{d=1}^D \alpha_d!}} \cdot \prod_{d=1}^D \left(x^{\{i\}}_d\right)^{\alpha_d} \right] \cdot \left[ \exp\left( -\gamma\left\|x^{\{j\}}\right\|^2 \right) \cdot \sqrt{\frac{(2\gamma)^m}{\prod_{d=1}^D \alpha_d!}} \cdot \prod_{d=1}^D \left(x^{\{j\}}_d\right)^{\alpha_d} \right] \\
    &\text{Now, WLOG, let's reindex the double-sum for clarity.} \\
    &\text{Let }A=[\alpha_1, \alpha_2, \cdots]\text{ be the infinite sequence of all multi-index sequences we need to consider for all }m \\
    K[i, j] &= \sum_{\forall\boldsymbol{\alpha}\in A}\left[ \exp\left( -\gamma\left\|x^{\{i\}}\right\|^2 \right) \cdot \sqrt{\frac{(2\gamma)^{\Sigma\boldsymbol{\alpha}}}{\prod_{d=1}^D \alpha_d!}} \cdot \prod_{d=1}^D \left(x^{\{i\}}_d\right)^{\alpha_d} \right] \cdot \left[ \exp\left( -\gamma\left\|x^{\{j\}}\right\|^2 \right) \cdot \sqrt{\frac{(2\gamma)^{\Sigma\boldsymbol{\alpha}}}{\prod_{d=1}^D \alpha_d!}} \cdot \prod_{d=1}^D \left(x^{\{j\}}_d\right)^{\alpha_d} \right] \\
    &\text{Let }\phi\text{ be a map }\mathbb{R}^D\rightarrow\mathbb{R}^\infty\text{ (technically, }\mathbb{R}^D\rightarrow\ell^2\cong\mathcal{H}\text{), with an infinite number of components, each corresponding to unique multi-index sequences} \\
    &\text{Let }\phi_{\boldsymbol{\alpha}}\text{ denote the scalar component of }\phi\text{ corresponding to a particular multi-index sequence }\boldsymbol{\alpha} \\
    \phi_{\boldsymbol{\alpha}}(x) &:= \exp\left( -\gamma\left\|x\right\|^2 \right) \cdot \sqrt{\frac{(2\gamma)^{\Sigma\boldsymbol{\alpha}}}{\prod_{d=1}^D \alpha_d!}} \cdot \prod_{d=1}^D \left(x_d\right)^{\alpha_d} \\
    &\text{Plugging in this definition,} \\
    K[i, j] &= \sum_{\forall\boldsymbol{\alpha}\in A} \phi_{\boldsymbol{\alpha}}(x^{\{i\}})\cdot \phi_{\boldsymbol{\alpha}}(x^{\{j\}}) \\
    K[i, j] &= \phi(x^{\{i\}})\cdot \phi(x^{\{j\}})
\end{align*}

    \subparagraph{Implementation}\label{implementation}

    So, as shown, the simple kernel
\[K[i, j] = \exp\left( -\gamma\left\|x^{\{i\}}-x^{\{j\}}\right\|^2 \right)\]
really does correspond uniquely to an infinite inner-product with the
infinite mapping: \[K[i, j] = \phi(x^{\{i\}})\cdot \phi(x^{\{j\}})\]
\[\phi(x)=\left[ \exp\left( -\gamma\left\|x\right\|^2 \right) \cdot \sqrt{\frac{(2\gamma)^{\Sigma\alpha_1}}{\prod_{d=1}^D \alpha_{1,d}!}} \cdot \prod_{d=1}^D \left(x_d\right)^{\alpha_{1,d}},\;\;\; \exp\left( -\gamma\left\|x\right\|^2 \right) \cdot \sqrt{\frac{(2\gamma)^{\Sigma\alpha_2}}{\prod_{d=1}^D \alpha_{2,d}!}} \cdot \prod_{d=1}^D \left(x_d\right)^{\alpha_{2,d}},\;\;\; \cdots \right]\]

Since the vector components decrease very quickly as the values in the
multi-indices increase (and you can't have infinitely many multi-indices
below some bound), up to some precision, you could map out an
approximation for \(\phi(x^{\{i\}})\) and do that for all pairs and fill
out the kernel in the same way you filled out the previous polynomial
kernel. But the essence of the kernel trick is that you really never
need to deal with the implicit functor \(\phi\), you just need to build
out the kernel.

    In \texttt{svm.py} complete \texttt{rbf\_kernel}.

You're also fine to use loops here. Though RBF tends to be quite good,
one major weakness of kernel-based SVM is that it requires
\(\mathcal{O}(N^2)\) space. While we're getting better volumetric
storage density and storage cost, if you have 1 million datapoints,
which isn't even close to a lot these days, you need 500 billion kernel
entries. No point in getting constant-time speedups if you can't even
allocate enough storage to store the output. So, no need to make your
code timely (we won't give you massive inputs that stall out the
Gradescope time).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{39}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestSVM}

\PY{n}{TestSVM}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}rbf\PYZus{}kernel}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}rbf\PYZus{}kernel}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_rbf\_kernel passed!
    \end{Verbatim}

    \subsection{\texorpdfstring{Q4: Next Character Prediction using
Recurrent Neural Networks (RNNs) {[}7.5\% Bonus for All{]}
{\textbf{{[}P{]}}} \textbar{}
{\textbf{{[}W{]}}}}{Q4: Next Character Prediction using Recurrent Neural Networks (RNNs) {[}7.5\% Bonus for All{]} {[}P{]} \textbar{} {[}W{]}}}\label{q4-next-character-prediction-using-recurrent-neural-networks-rnns-7.5-bonus-for-all-p-w}

    Recurrent Neural Networks are a class of neural networks designed to
handle sequential or time-series data, where the order of inputs
matters. Unlike feedforward neural networks that treat each input
independently, sequential networks maintain memory of previous inputs,
making them ideal for tasks involving ordered data like text, time
series, or video frames. These networks allow previous outputs to be
used as inputs while having hidden states.

Common applications include: - Text processing (language modeling,
translation) - Machine translation (translating from one language to the
other) - Time series prediction (stock prices, weather forecasting)

In this section, we'll compare two foundational types of recurrent
neural network architectures: Simple Recurrent Neural Networks (Simple
RNNs) and Long Short-Term Memory networks (LSTMs). The goal is to train
these models to generate text in the style of Macbeth by predicting the
next character in a given sequence. This exercise will highlight how
each architecture manages sequential dependencies in text generation.

Check out the guide under \texttt{utilities/q5\_guide} for more details
on RNNs.

    \subsubsection{Data Preparation}\label{data-preparation}

    \begin{itemize}
\item
  We'll use Shakespeare's Macbeth from Project Gutenberg
\item
  We vectorize the text by treating every character in our text as an
  individual unit (e.g., `macbeth' -\textgreater{} {[}`m', `a',
  `c'\ldots{]})
\item
  We use a dictionary to store this mapping: \{`a':1, `b':2, `c':3,
  \ldots\}
\item
  This mapping enables bidirectional conversion between characters and
  integers for model input and output interpretation
\item
  We assign each each character a learnable embedding vector
\item
  Create fixed-sized batches of characters using sliding window approach
\item
  For example, with text ``macbeth'' (context window=4):

\begin{verbatim}
Window 1: "macb"  predict "e"
Window 2: "acbe"  predict "t"
Window 3: "cbet"  predict "h"
\end{verbatim}
\end{itemize}

Our final preprocessed data contains: - \textbf{X}: Input sequences -
(shape: {[}\texttt{NUM\_SEQUENCES}, \texttt{SEQUENCE\_LEN}{]}) -
Contains all character sequences of length SEQUENCE\_LEN - \textbf{Y}:
Target characters - (shape: {[}\texttt{NUM\_SEQUENCES}, \texttt{1}{]}) -
Contains the next character that follows each sequence in X -
\textbf{VOCABULARY MAP}: The mapping from all unique characters in the
text and their numerical representations - \textbf{VOCAB\_SIZE}: Total
number of unique characters - \textbf{SEQUENCE\_LEN}: Length of input
sequences

You can also refer to \texttt{preprocess\_text\_data} located in
utilities\textgreater utils.py for more details.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{40}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{preprocess\PYZus{}text\PYZus{}data}

\PY{c+c1}{\PYZsh{} load and preprocess text}
\PY{n}{text} \PY{o}{=} \PY{n}{requests}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{https://www.gutenberg.org/files/1533/1533\PYZhy{}0.txt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{text}
\PY{n}{DATA} \PY{o}{=} \PY{n}{preprocess\PYZus{}text\PYZus{}data}\PY{p}{(}\PY{n}{text}\PY{p}{)}

\PY{c+c1}{\PYZsh{} unpack processed data components}
\PY{n}{X}\PY{p}{,} \PY{n}{Y}\PY{p}{,} \PY{n}{TEXT}\PY{p}{,} \PY{n}{CHAR\PYZus{}INDICES}\PY{p}{,} \PY{n}{INDICES\PYZus{}CHAR}\PY{p}{,} \PY{n}{VOCAB}\PY{p}{,} \PY{n}{VOCAB\PYZus{}SIZE}\PY{p}{,} \PY{n}{SEQUENCE\PYZus{}LEN} \PY{o}{=} \PY{p}{(}
    \PY{n}{DATA}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{DATA}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{DATA}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{text}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{DATA}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{char\PYZus{}indices}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{DATA}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{indices\PYZus{}char}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{DATA}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{vocab}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{DATA}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{vocab\PYZus{}size}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{n}{DATA}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sequence\PYZus{}len}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Length of Corpus: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{TEXT}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Vocabulary Map: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{CHAR\PYZus{}INDICES}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Vocabulary Size: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{VOCAB\PYZus{}SIZE}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{X shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Y shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{Y}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Length of Corpus:  102176
Vocabulary Map:  \{' ': 0, '!': 1, ',': 2, '-': 3, '.': 4, '1': 5, '3': 6, '5':
7, ':': 8, ';': 9, '?': 10, 'a': 11, 'b': 12, 'c': 13, 'd': 14, 'e': 15, 'f':
16, 'g': 17, 'h': 18, 'i': 19, 'j': 20, 'k': 21, 'l': 22, 'm': 23, 'n': 24, 'o':
25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'x':
34, 'y': 35, 'z': 36\}
Vocabulary Size:  37
X shape: (102146, 30)
Y shape: (102146, 1)
    \end{Verbatim}

    \subsubsection{\texorpdfstring{4.1 Model Architecture {[}5\% Bonus for
All{]}
{\textbf{{[}P{]}}}}{4.1 Model Architecture {[}5\% Bonus for All{]} {[}P{]}}}\label{model-architecture-5-bonus-for-all-p}

    Before diving into the specific architectures, let's understand how data
shapes transform through the embedding layer.

Input Sequence Shape Flow: 1. Initial input:
\texttt{(BATCH\_SIZE,\ SEQUENCE\_LEN)} - \texttt{BATCH\_SIZE} sequences
containing \texttt{SEQUENCE\_LEN} integers, where each integer
represents a character from our vocabulary - Example: If
\texttt{BATCH\_SIZE=32} and \texttt{SEQUENCE\_LEN=15}, shape is
\texttt{(32,\ 15)}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Embedding Layer:
  \texttt{(BATCH\_SIZE,\ SEQUENCE\_LEN,\ EMBEDDING\_DIM)}

  \begin{itemize}
  \tightlist
  \item
    Transforms each integer into a vector of size
    \texttt{EMBEDDING\_DIM}
  \item
    Example: If \texttt{EMBEDDING\_DIM=64}:

    \begin{itemize}
    \tightlist
    \item
      Each character index becomes a vector of 64 numbers
    \item
      Shape expands from \texttt{(32,\ 15)} to \texttt{(32,\ 15,\ 64)}
    \item
      This means: 32 sequences, each 15 characters long, each character
      now represented by 64 numbers
    \end{itemize}
  \end{itemize}
\end{enumerate}

    \paragraph{4.1.1 Defining the Simple RNN
Model}\label{defining-the-simple-rnn-model}

    In this part, you need to build a simple recurrent neural network using
PyTorch. The architecture of the model is outlined below:

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio,alt={rnn\_architecture}]{data/images/rnn_architecture.png}}
\caption{rnn\_architecture}
\end{figure}

\textbf{{[}EMBEDDING - RNN - ADAPTER - FC{]}} \textgreater{}
\textbf{EMBEDDING}: The Embedding layer maps each integer (representing
a character) in the input sequence to a dense vector representation.
Each character index becomes a vector of \textbf{embedding dimension}.
It has an input dimension of \textbf{vocab\_size} (the total number of
unique characters or tokens) and an output dimension defined by
\textbf{embedding\_dim}. This transformation allows the model to capture
semantic relationships in the data. \textgreater{} - Input shape:
(batch\_size, sequence\_length) - A sequence of character indices
\textgreater{} - Output shape: (batch\_size, sequence\_length,
embedding\_dim) - Each character transformed into an embedding vector

\begin{quote}
\textbf{RNN}: This layer processes the sequence data, passing
information through time steps to learn temporal patterns. It has
\textbf{rnn\_units} neurons, determining the model's ability to capture
dependencies in the sequential data. - Input shape: (batch\_size,
sequence\_length, embedding\_dim) - Sequence of embedding vectors -
Output shape: (batch\_size, rnn\_units) - Final state output
\end{quote}

\begin{quote}
\textbf{RNNOutputAdapter}: Helper function implemented to ensure that
the pass to the next layer is of correct dimentionality - Input shape
(as a tuple): (full\_sequence\_output of shape (batch\_size,
sequence\_length, rnn\_units), - final\_hidden\_state of shape (1,
batch\_size, rnn\_units)) - Output shape: (batch\_size, rnn\_units)
\end{quote}

\begin{quote}
\textbf{FC (Dense Layer)}: A fully connected layer that transforms the
RNN output to match the number of classes or possible output tokens. It
has \textbf{vocab\_size} neurons, ensuring that each output corresponds
to a unique token or class. - Input shape: (batch\_size, rnn\_units) -
RNN final state - Output shape: (batch\_size, vocab\_size) - Raw scores
for each possible character
\end{quote}

You can refer to the following documentation on PyTorch layers for more
details: -
\href{https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html}{Embedding}
-
\href{https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html}{RNN}
-
\href{https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html}{Dense}

TODO: Implement the define\_model function in rnn.py.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{41}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{rnn}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{RNN}

\PY{n}{rnn\PYZus{}model} \PY{o}{=} \PY{n}{RNN}\PY{p}{(}\PY{n}{VOCAB\PYZus{}SIZE}\PY{p}{,} \PY{n}{SEQUENCE\PYZus{}LEN}\PY{p}{)}
\PY{n}{rnn\PYZus{}model}\PY{o}{.}\PY{n}{set\PYZus{}hyperparameters}\PY{p}{(}\PY{p}{)}
\PY{n}{rnn\PYZus{}model}\PY{o}{.}\PY{n}{define\PYZus{}model}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{42}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestRNN}

\PY{n}{tester} \PY{o}{=} \PY{n}{TestRNN}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}rnn\PYZus{}architecture}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}rnn\PYZus{}architecture}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_rnn\_architecture passed!
    \end{Verbatim}

    \paragraph{4.1.2 Defining the LSTM Model}\label{defining-the-lstm-model}

    In this part, you need to build a long short-term memory (LSTM) network
as described below. The architecture of the model is outlined below:

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio,alt={lstm\_architecture}]{data/images/lstm_architecture.png}}
\caption{lstm\_architecture}
\end{figure}

\textbf{{[}EMBEDDING - LSTM - ADAPTER - FC{]}} \textgreater{}
\textbf{EMBEDDING}: The Embedding layer maps each integer in the input
sequence to a dense vector representation. It has an input dimension of
\textbf{vocab\_size} (the total number of unique characters or tokens)
and an output dimension defined by \textbf{embedding\_dim}. This
transformation allows the model to capture semantic relationships in the
data. \textgreater{} - Input shape: (batch\_size, sequence\_length) - A
sequence of character indices \textgreater{} - Output shape:
(batch\_size, sequence\_length, embedding\_dim) - Each character
transformed into an embedding vector

\begin{quote}
\textbf{LSTM}: This layer processes the sequence data, passing
information through time steps to learn temporal patterns. It has
\textbf{lstm\_units} neurons, determining the LSTM ability to capture
dependencies in the sequential data. - Input shape: (batch\_size,
sequence\_length, embedding\_dim) - Sequence of embedding vectors -
Output shape: (batch\_size, lstm\_units) - Final state output
\end{quote}

\begin{quote}
\textbf{LSTMOutputAdapter}: Helper function implemented to ensure that
the pass to the next layer is of correct dimentionality - Input shape
(as a tuple): (full\_sequence\_output of shape (batch\_size,
sequence\_length, rnn\_units), - final\_hidden\_state of shape (1,
batch\_size, rnn\_units)) - Output shape: (batch\_size, rnn\_units)
\end{quote}

\begin{quote}
\textbf{FC (Dense Layer)}: A fully connected layer that transforms the
LSTM output to match the number of classes or possible output tokens. It
has \textbf{vocab\_size} neurons, ensuring that each output corresponds
to a unique token or class. - Input shape: (batch\_size, lstm\_units) -
LSTM final state - Output shape: (batch\_size, vocab\_size) - Raw scores
for each possible character
\end{quote}

You can refer to the following documentation on PyTorch layers for more
details: -
\href{https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html}{Embedding}
-
\href{https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html}{LSTM}
-
\href{https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html}{Dense}

TODO: Implement the define\_model function in lstm.py.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{43}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{lstm}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{LSTM}

\PY{n}{lstm\PYZus{}model} \PY{o}{=} \PY{n}{LSTM}\PY{p}{(}\PY{n}{VOCAB\PYZus{}SIZE}\PY{p}{,} \PY{n}{SEQUENCE\PYZus{}LEN}\PY{p}{)}
\PY{n}{lstm\PYZus{}model}\PY{o}{.}\PY{n}{set\PYZus{}hyperparameters}\PY{p}{(}\PY{p}{)}
\PY{n}{lstm\PYZus{}model}\PY{o}{.}\PY{n}{define\PYZus{}model}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{44}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{utilities}\PY{n+nn}{.}\PY{n+nn}{localtests}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TestLSTM}

\PY{n}{tester} \PY{o}{=} \PY{n}{TestLSTM}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}lstm\PYZus{}architecture}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{test\PYZus{}lstm\PYZus{}architecture}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
test\_lstm\_architecture passed!
    \end{Verbatim}

    \subsubsection{\texorpdfstring{4.2 RNN vs LSTM Model Text Generation
Training Comparison Analysis {[}2.5\% Bonus for All{]}
{\textbf{{[}W{]}}}}{4.2 RNN vs LSTM Model Text Generation Training Comparison Analysis {[}2.5\% Bonus for All{]} {[}W{]}}}\label{rnn-vs-lstm-model-text-generation-training-comparison-analysis-2.5-bonus-for-all-w}

    \paragraph{Training Configuration}\label{training-configuration}

    \begin{itemize}
\tightlist
\item
  \textbf{Optimizer}: RMSprop (Root Mean Square Propagation) optimizer
  for efficient training of recurrent networks. Read more about it
  \href{https://docs.pytorch.org/docs/stable/generated/torch.optim.RMSprop.html}{here}.
\item
  \textbf{Loss Function}: Categorical crossentropy to measure accuracy
  of predicted probability distribution. Read more about it
  \href{https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html}{here}.
\item
  \textbf{Training Parameters}: Number of epochs and batch size are
  defined in the hyperparameters section of \texttt{rnn.py} and
  \texttt{lstm.py} respectively
\end{itemize}

The core training loop implementation can be found in
\texttt{base\_sequential\_model.py}. A plot showing loss metrics across
epochs will be generated after training completes.

NOTE: The initial model training may take 10-15 minutes per model. After
that, the function will automatically load the saved weights stored in
the \texttt{rnn\_model\_weights} directory, making subsequent runs much
faster. If you want to retrain from scratch instead of using saved
weights, you can either: - Set \texttt{train\_from\_scratch=True} in the
parameters - Delete the existing weights from the
\texttt{rnn\_model\_weights} directory

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{45}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{n}{rnn\PYZus{}model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{Y}\PY{p}{,} \PY{n}{train\PYZus{}from\PYZus{}scratch}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{rnn\PYZus{}model}\PY{o}{.}\PY{n}{plot\PYZus{}loss}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Training RNN model from scratch{\ldots}
Epoch 1/10, Loss: 1.9891
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 2/10, Loss: 1.7758
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 3/10, Loss: 1.6964
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 4/10, Loss: 1.6467
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 5/10, Loss: 1.6124
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 6/10, Loss: 1.5882
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 7/10, Loss: 1.5658
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 8/10, Loss: 1.5501
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 9/10, Loss: 1.5378
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Epoch 10/10, Loss: 1.5236
  Saved best model to rnn\_model\_weights/RNN\_weights.pth
Finished training. Best model weights saved to rnn\_model\_weights/RNN\_weights.pth
Saved RNN model loss history to rnn\_model\_weights/RNN\_losses.json
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_207_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{46}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{n}{lstm\PYZus{}model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{Y}\PY{p}{,} \PY{n}{train\PYZus{}from\PYZus{}scratch}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{lstm\PYZus{}model}\PY{o}{.}\PY{n}{plot\PYZus{}loss}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Training LSTM model from scratch{\ldots}
Epoch 1/10, Loss: 1.9696
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 2/10, Loss: 1.7319
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 3/10, Loss: 1.6408
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 4/10, Loss: 1.5851
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 5/10, Loss: 1.5424
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 6/10, Loss: 1.5062
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 7/10, Loss: 1.4783
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 8/10, Loss: 1.4528
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 9/10, Loss: 1.4305
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Epoch 10/10, Loss: 1.4117
  Saved best model to rnn\_model\_weights/LSTM\_weights.pth
Finished training. Best model weights saved to
rnn\_model\_weights/LSTM\_weights.pth
Saved LSTM model loss history to rnn\_model\_weights/LSTM\_losses.json
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{HW4_files/HW4_208_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    We can now generate text in the style of Macbeth by recursively:

\begin{itemize}
\tightlist
\item
  Sampling next character using model's predicted probabilities
\item
  Including the generated character in current window, and generate the
  next character
\end{itemize}

You can refer to text\_generator.py for more details.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{text\PYZus{}generator}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TextGenerator}

\PY{n}{generator} \PY{o}{=} \PY{n}{TextGenerator}\PY{p}{(}\PY{n}{CHAR\PYZus{}INDICES}\PY{p}{,} \PY{n}{INDICES\PYZus{}CHAR}\PY{p}{,} \PY{n}{SEQUENCE\PYZus{}LEN}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{48}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} DO NOT CHANGE THIS CELL \PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{n}{start\PYZus{}index} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{TEXT}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{SEQUENCE\PYZus{}LEN} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{seed\PYZus{}text} \PY{o}{=} \PY{n}{TEXT}\PY{p}{[}\PY{n}{start\PYZus{}index} \PY{p}{:} \PY{n}{start\PYZus{}index} \PY{o}{+} \PY{n}{SEQUENCE\PYZus{}LEN}\PY{p}{]}

\PY{n}{generator}\PY{o}{.}\PY{n}{generate}\PY{p}{(}
    \PY{n}{model\PYZus{}wrapper}\PY{o}{=}\PY{n}{rnn\PYZus{}model}\PY{p}{,} \PY{n}{seed\PYZus{}text}\PY{o}{=}\PY{n}{seed\PYZus{}text}\PY{p}{,} \PY{n}{length}\PY{o}{=}\PY{l+m+mi}{150}\PY{p}{,} \PY{n}{temperature}\PY{o}{=}\PY{l+m+mf}{0.75}
\PY{p}{)}
\PY{n}{generator}\PY{o}{.}\PY{n}{generate}\PY{p}{(}
    \PY{n}{model\PYZus{}wrapper}\PY{o}{=}\PY{n}{lstm\PYZus{}model}\PY{p}{,} \PY{n}{seed\PYZus{}text}\PY{o}{=}\PY{n}{seed\PYZus{}text}\PY{p}{,} \PY{n}{length}\PY{o}{=}\PY{l+m+mi}{150}\PY{p}{,} \PY{n}{temperature}\PY{o}{=}\PY{l+m+mf}{0.75}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
-------------------- RNN Model --------------------
Prompt: and tartars lips, finger of bi
Model: ve to the concount of clead eal thou desirpt diest to double the father a
for a plore, witch. i ladid come, and your my deare. but birness of an done.
-------------------- LSTM Model --------------------
Prompt: and tartars lips, finger of bi
Model: rd, and that men. macduff. does your suppress with full and father
pocking two the have such an i have be the tworth, well that within. theres to a
mo
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{48}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
'rd, and that men. macduff. does your suppress with full and father pocking two
the have such an i have be the tworth, well that within. theres to a mo'
\end{Verbatim}
\end{tcolorbox}
        
    \paragraph{Written Question}\label{written-question}

    Analyze your experience training Simple RNN and LSTM models for Macbeth
character prediction and answer the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify and explain a real-world application where Simple RNN would
  be more suitable than LSTM
\item
  Identify and explain a real-world application where LSTM would be more
  suitable than Simple RNN
\end{enumerate}

For each case, support your answer using evidence from atleast 1 metric
observed during training and 1 other metric. For the observed metric,
please include specific evidence from the training in the notebook.

Some ideas for metrics you can consider:

\begin{itemize}
\tightlist
\item
  Inference time / Training time
\item
  Final Loss Achieved
\item
  Generated Text Quality
\item
  Memory requirements
\item
  Loss convergence
\item
  Simplicity of architecture
\end{itemize}

    \textbf{YOUR ANSWER HERE}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

The LTSM achieved a lower loss than the RNN: 1.4117 compared to 1.5236,
respectively. The output of the LTSM also generated coherent text, while
the RNN didn't really. Thus, an RNN would be more suitable for
short-context, resource-constrained tasks like. In contrast, LSTMs are
more suitable for stuff like language modeling or translation that
require long-range context.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \subsection{Carbon Impact}\label{carbon-impact}

    Running this notebook generates carbon emissions that we can measure.
For context, a typical passenger vehicle emits approximately 200 grams
of CO for each kilometer driven. Below, we compare our computational
carbon cost to this everyday activity.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{49}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{emissions} \PY{o}{=} \PY{n}{tracker}\PY{o}{.}\PY{n}{stop}\PY{p}{(}\PY{p}{)}

\PY{n}{car\PYZus{}emissions\PYZus{}per\PYZus{}km} \PY{o}{=} \PY{l+m+mf}{0.17}  \PY{c+c1}{\PYZsh{} kg CO2e/km driven}
\PY{c+c1}{\PYZsh{} CO2e is a measure of the amount of CO2 that would be equivalent to actual emissions in terms of warming}
\PY{c+c1}{\PYZsh{} (some gasses have a higher warming effect over 100 years than CO2, e.g., your car probably emits a bit of SO2, 1g SO2 = 25g CO2e)}
\PY{n}{students} \PY{o}{=} \PY{l+m+mi}{900}
\PY{n}{equivalent\PYZus{}distance\PYZus{}per\PYZus{}student} \PY{o}{=} \PY{n}{emissions} \PY{o}{/} \PY{n}{car\PYZus{}emissions\PYZus{}per\PYZus{}km}
\PY{n}{equivalent\PYZus{}distance\PYZus{}all} \PY{o}{=} \PY{n}{emissions} \PY{o}{*} \PY{n}{students} \PY{o}{/} \PY{n}{car\PYZus{}emissions\PYZus{}per\PYZus{}km}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Total emissions in this session: }\PY{l+s+si}{\PYZob{}}\PY{n}{emissions}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ kg CO2e}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}
    \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{This session is equivalent to driving }\PY{l+s+si}{\PYZob{}}\PY{n}{equivalent\PYZus{}distance\PYZus{}per\PYZus{}student}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{km in an average car}\PY{l+s+s2}{\PYZdq{}}
\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}
    \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Driving Equivalent for all }\PY{l+s+si}{\PYZob{}}\PY{n}{students}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ students: }\PY{l+s+si}{\PYZob{}}\PY{n}{equivalent\PYZus{}distance\PYZus{}all}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ km driven in an average car}\PY{l+s+s2}{\PYZdq{}}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Total emissions in this session: 0.251613481196112 kg CO2e
This session is equivalent to driving 1.48km in an average car

Driving Equivalent for all 900 students: 1332.07 km driven in an average car
    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
